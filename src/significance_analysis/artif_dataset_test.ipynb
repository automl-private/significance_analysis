{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the mixed effects model\n",
    "from patsy import dmatrix\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_rows\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 5000)\n",
    "pd.set_option(\"display.width\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Mixed Linear Model Regression Results\n",
      "===================================================================================\n",
      "Model:                     MixedLM         Dependent Variable:         mean        \n",
      "No. Observations:          180000          Method:                     ML          \n",
      "No. Groups:                4               Scale:                      53.4669     \n",
      "Min. group size:           45000           Log-Likelihood:             -613546.8042\n",
      "Max. group size:           45000           Converged:                  Yes         \n",
      "Mean group size:           45000.0                                                 \n",
      "-----------------------------------------------------------------------------------\n",
      "                                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept                                 5.760    4.374  1.317 0.188 -2.813 14.332\n",
      "acquisition[T.ProbabilityOfImprovement]   0.337    0.073  4.609 0.000  0.194  0.480\n",
      "acquisition[T.UpperConfidenceBound]       0.119    0.073  1.624 0.104 -0.025  0.262\n",
      "acquisition[T.qExpectedImprovement]       0.062    0.073  0.846 0.397 -0.081  0.205\n",
      "acquisition[T.qKnowledgeGradient]         0.495    0.073  6.773 0.000  0.352  0.639\n",
      "acquisition[T.qProbabilityOfImprovement]  0.523    0.073  7.155 0.000  0.380  0.666\n",
      "acquisition[T.qSimpleRegret]              0.096    0.073  1.319 0.187 -0.047  0.240\n",
      "acquisition[T.qUpperConfidenceBound]      0.153    0.073  2.090 0.037  0.010  0.296\n",
      "acquisition[T.randomSearch]               0.892    0.073 12.202 0.000  0.749  1.036\n",
      "benchmark Var                            76.513    6.062                           \n",
      "===================================================================================\n",
      "\n",
      "{'Branin': benchmark   -2.259813\n",
      "dtype: float64, 'Hartmann6': benchmark   -8.186249\n",
      "dtype: float64, 'Jahs_Bench': benchmark    16.499738\n",
      "dtype: float64, 'NN_HPO_Bench': benchmark   -6.053677\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset_copy_DELETEAFTER.csv\")\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "bins=[0,15,30,49]\n",
    "\n",
    "\n",
    "differentMeans_model = mixedlm(formula=f\"{metric} ~ {system_id}\", data=data, groups=input_id)\n",
    "diffModelFit = differentMeans_model.fit( reml=False)\n",
    "print(diffModelFit.summary())\n",
    "print(diffModelFit.random_effects)\n",
    "\n",
    "bins_set = set(bins)\n",
    "bins_set.add(data[bin_id].min())\n",
    "bins_set.add(data[bin_id].max())\n",
    "bins = sorted(list(bins_set))\n",
    "\n",
    "bin_labels = [f\"{bins[i]}_{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "\n",
    "data[f\"{bin_id}_bins\"] = pd.cut(\n",
    "    data[bin_id], bins=bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# New model \"expanded\": Divides into system AND bin-classes (Term system:bin_id allows for Cartesian Product, i.e. different Mean for each system and bin-class)\n",
    "model_expanded = Lmer(\n",
    "    f\"{metric} ~  {system_id} + {bin_id}_bins + {system_id}:{bin_id}_bins + (1 | {input_id})\",\n",
    "    data=data,\n",
    ")\n",
    "model_expanded.fit(factors={\n",
    "    system_id: list(data[system_id].unique()),\n",
    "    f\"{bin_id}_bins\": list(data[f\"{bin_id}_bins\"].unique())},\n",
    "REML=False,\n",
    "summarize=False,\n",
    ")\n",
    "#print(model_expanded.ranef)\n",
    "#print(\"\")\n",
    "#print(model_expanded.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid:\n",
      "                  acquisition\n",
      "0        ExpectedImprovement\n",
      "1   ProbabilityOfImprovement\n",
      "2       UpperConfidenceBound\n",
      "3       qExpectedImprovement\n",
      "4         qKnowledgeGradient\n",
      "5  qProbabilityOfImprovement\n",
      "6              qSimpleRegret\n",
      "7      qUpperConfidenceBound\n",
      "8               randomSearch\n",
      "Coeffs:\n",
      " Intercept                                   5.759636\n",
      "acquisition[T.ProbabilityOfImprovement]     0.336997\n",
      "acquisition[T.UpperConfidenceBound]         0.118736\n",
      "acquisition[T.qExpectedImprovement]         0.061894\n",
      "acquisition[T.qKnowledgeGradient]           0.495266\n",
      "acquisition[T.qProbabilityOfImprovement]    0.523160\n",
      "acquisition[T.qSimpleRegret]                0.096439\n",
      "acquisition[T.qUpperConfidenceBound]        0.152831\n",
      "acquisition[T.randomSearch]                 0.892227\n",
      "dtype: float64\n",
      "Matrix:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "                 acquisition     means        SE\n",
      "0        ExpectedImprovement  5.759636  4.373900\n",
      "1   ProbabilityOfImprovement  6.096633  4.374206\n",
      "2       UpperConfidenceBound  5.878372  4.374206\n",
      "3       qExpectedImprovement  5.821530  4.374206\n",
      "4         qKnowledgeGradient  6.254902  4.374206\n",
      "5  qProbabilityOfImprovement  6.282796  4.374206\n",
      "6              qSimpleRegret  5.856075  4.374206\n",
      "7      qUpperConfidenceBound  5.912468  4.374206\n",
      "8               randomSearch  6.651863  4.374206\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values for each level of system_id\n",
    "\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[input_id].unique(),\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(2, len(data[input_id].unique()) * len(data[system_id].unique())).T)\n",
    "\n",
    "grid = pd.DataFrame(grid, columns=[input_id, system_id)\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(1, len(data[system_id].unique())).T)\n",
    "grid = pd.DataFrame(grid, columns=[ system_id])\n",
    "print(\"Grid:\\n\",grid)\n",
    "betas = diffModelFit.fe_params\n",
    "print(\"Coeffs:\\n\",betas)\n",
    "mat = dmatrix(f\"C({system_id})\", grid, return_type=\"matrix\")\n",
    "print(\"Matrix:\\n\",mat)\n",
    "emmeans = grid.copy()\n",
    "emmeans[\"means\"] = mat @ betas\n",
    "#print(emmeans)\n",
    "vcov = diffModelFit.cov_params()\n",
    "# print(vcov)\n",
    "\n",
    "vcov = vcov[~vcov.index.str.contains(\"Var|Cor\")]\n",
    "vcov = vcov.loc[:, ~vcov.columns.str.contains(\"Var|Cor\")]\n",
    "#print(vcov)\n",
    "emmeans[\"SE\"] = np.sqrt(np.diagonal(mat @ vcov) @ mat.T)\n",
    "print(emmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Multiple Comparison of Means - Tukey HSD, FWER=0.05                    \n",
      "==========================================================================================\n",
      "          group1                    group2          meandiff p-adj   lower   upper  reject\n",
      "------------------------------------------------------------------------------------------\n",
      "      ExpectedImprovement  ProbabilityOfImprovement   0.2949    0.0  0.2104  0.3795   True\n",
      "      ExpectedImprovement      UpperConfidenceBound   0.0517 0.5732 -0.0329  0.1363  False\n",
      "      ExpectedImprovement      qExpectedImprovement   0.0088    1.0 -0.0758  0.0934  False\n",
      "      ExpectedImprovement        qKnowledgeGradient   0.4299    0.0  0.3453  0.5145   True\n",
      "      ExpectedImprovement qProbabilityOfImprovement   0.4402    0.0  0.3556  0.5248   True\n",
      "      ExpectedImprovement             qSimpleRegret   0.0285 0.9746 -0.0561  0.1131  False\n",
      "      ExpectedImprovement     qUpperConfidenceBound   0.1307 0.0002  0.0461  0.2153   True\n",
      "      ExpectedImprovement              randomSearch   0.8213    0.0  0.7367  0.9059   True\n",
      " ProbabilityOfImprovement      UpperConfidenceBound  -0.2432    0.0 -0.3278 -0.1586   True\n",
      " ProbabilityOfImprovement      qExpectedImprovement  -0.2861    0.0 -0.3707 -0.2015   True\n",
      " ProbabilityOfImprovement        qKnowledgeGradient   0.1349 0.0001  0.0503  0.2195   True\n",
      " ProbabilityOfImprovement qProbabilityOfImprovement   0.1452    0.0  0.0606  0.2298   True\n",
      " ProbabilityOfImprovement             qSimpleRegret  -0.2664    0.0  -0.351 -0.1818   True\n",
      " ProbabilityOfImprovement     qUpperConfidenceBound  -0.1643    0.0 -0.2489 -0.0797   True\n",
      " ProbabilityOfImprovement              randomSearch   0.5264    0.0  0.4418   0.611   True\n",
      "     UpperConfidenceBound      qExpectedImprovement  -0.0429 0.7855 -0.1275  0.0417  False\n",
      "     UpperConfidenceBound        qKnowledgeGradient   0.3781    0.0  0.2935  0.4627   True\n",
      "     UpperConfidenceBound qProbabilityOfImprovement   0.3884    0.0  0.3038   0.473   True\n",
      "     UpperConfidenceBound             qSimpleRegret  -0.0232 0.9932 -0.1078  0.0614  False\n",
      "     UpperConfidenceBound     qUpperConfidenceBound   0.0789 0.0861 -0.0057  0.1635  False\n",
      "     UpperConfidenceBound              randomSearch   0.7696    0.0   0.685  0.8542   True\n",
      "     qExpectedImprovement        qKnowledgeGradient    0.421    0.0  0.3364  0.5056   True\n",
      "     qExpectedImprovement qProbabilityOfImprovement   0.4313    0.0  0.3467  0.5159   True\n",
      "     qExpectedImprovement             qSimpleRegret   0.0197 0.9978 -0.0649  0.1043  False\n",
      "     qExpectedImprovement     qUpperConfidenceBound   0.1218 0.0006  0.0372  0.2064   True\n",
      "     qExpectedImprovement              randomSearch   0.8125    0.0  0.7279  0.8971   True\n",
      "       qKnowledgeGradient qProbabilityOfImprovement   0.0103    1.0 -0.0743  0.0949  False\n",
      "       qKnowledgeGradient             qSimpleRegret  -0.4013    0.0 -0.4859 -0.3167   True\n",
      "       qKnowledgeGradient     qUpperConfidenceBound  -0.2992    0.0 -0.3838 -0.2146   True\n",
      "       qKnowledgeGradient              randomSearch   0.3915    0.0  0.3069  0.4761   True\n",
      "qProbabilityOfImprovement             qSimpleRegret  -0.4116    0.0 -0.4962  -0.327   True\n",
      "qProbabilityOfImprovement     qUpperConfidenceBound  -0.3095    0.0 -0.3941 -0.2249   True\n",
      "qProbabilityOfImprovement              randomSearch   0.3811    0.0  0.2966  0.4657   True\n",
      "            qSimpleRegret     qUpperConfidenceBound   0.1021 0.0073  0.0175  0.1867   True\n",
      "            qSimpleRegret              randomSearch   0.7928    0.0  0.7082  0.8774   True\n",
      "    qUpperConfidenceBound              randomSearch   0.6907    0.0  0.6061  0.7753   True\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "grid[input_id]=data[input_id].unique()[0]\n",
    "n=9\n",
    "sample_size=8\n",
    "emmeans[\"SD\"] = emmeans[\"SE\"]/(n**2)\n",
    "#print(\"Grid:\\n\",grid)\n",
    "predicted_values = pd.DataFrame()\n",
    "data_list=[]\n",
    "for acqu in emmeans[system_id]:\n",
    "    #print(emmeans.loc[emmeans[system_id]==acqu][\"means\"],emmeans.loc[emmeans[system_id]==acqu][\"SD\"])\n",
    "    artif_data=np.random.normal(emmeans.loc[emmeans[system_id]==acqu][\"means\"],emmeans.loc[emmeans[system_id]==acqu][\"SD\"],sample_size)\n",
    "    data_list.extend(artif_data)\n",
    "predicted_values[\"data\"]=data_list\n",
    "predicted_values[\"names\"]=np.repeat(list(emmeans[system_id]),sample_size)\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "print(pairwise_tukeyhsd(predicted_values[\"data\"],predicted_values[\"names\"],0.05))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
