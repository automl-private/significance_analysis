{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the mixed effects model\n",
    "from patsy import dmatrix\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_rows\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 5000)\n",
    "pd.set_option(\"display.width\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Mixed Linear Model Regression Results\n",
      "===================================================================================\n",
      "Model:                     MixedLM         Dependent Variable:         mean        \n",
      "No. Observations:          180000          Method:                     ML          \n",
      "No. Groups:                4               Scale:                      53.4669     \n",
      "Min. group size:           45000           Log-Likelihood:             -613546.8042\n",
      "Max. group size:           45000           Converged:                  Yes         \n",
      "Mean group size:           45000.0                                                 \n",
      "-----------------------------------------------------------------------------------\n",
      "                                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept                                 5.760    4.374  1.317 0.188 -2.813 14.332\n",
      "acquisition[T.ProbabilityOfImprovement]   0.337    0.073  4.609 0.000  0.194  0.480\n",
      "acquisition[T.UpperConfidenceBound]       0.119    0.073  1.624 0.104 -0.025  0.262\n",
      "acquisition[T.qExpectedImprovement]       0.062    0.073  0.846 0.397 -0.081  0.205\n",
      "acquisition[T.qKnowledgeGradient]         0.495    0.073  6.773 0.000  0.352  0.639\n",
      "acquisition[T.qProbabilityOfImprovement]  0.523    0.073  7.155 0.000  0.380  0.666\n",
      "acquisition[T.qSimpleRegret]              0.096    0.073  1.319 0.187 -0.047  0.240\n",
      "acquisition[T.qUpperConfidenceBound]      0.153    0.073  2.090 0.037  0.010  0.296\n",
      "acquisition[T.randomSearch]               0.892    0.073 12.202 0.000  0.749  1.036\n",
      "benchmark Var                            76.513    6.062                           \n",
      "===================================================================================\n",
      "\n",
      "{'Branin': benchmark   -2.259813\n",
      "dtype: float64, 'Hartmann6': benchmark   -8.186249\n",
      "dtype: float64, 'Jahs_Bench': benchmark    16.499738\n",
      "dtype: float64, 'NN_HPO_Bench': benchmark   -6.053677\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset_copy_DELETEAFTER.csv\")\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "bins=[0,15,30,49]\n",
    "\n",
    "\n",
    "differentMeans_model = mixedlm(formula=f\"{metric} ~ {system_id}\", data=data, groups=input_id)\n",
    "diffModelFit = differentMeans_model.fit( reml=False)\n",
    "print(diffModelFit.summary())\n",
    "print(diffModelFit.random_effects)\n",
    "\n",
    "bins_set = set(bins)\n",
    "bins_set.add(data[bin_id].min())\n",
    "bins_set.add(data[bin_id].max())\n",
    "bins = sorted(list(bins_set))\n",
    "\n",
    "bin_labels = [f\"{bins[i]}_{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "\n",
    "data[f\"{bin_id}_bins\"] = pd.cut(\n",
    "    data[bin_id], bins=bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# New model \"expanded\": Divides into system AND bin-classes (Term system:bin_id allows for Cartesian Product, i.e. different Mean for each system and bin-class)\n",
    "model_expanded = Lmer(\n",
    "    f\"{metric} ~  {system_id} + {bin_id}_bins + {system_id}:{bin_id}_bins + (1 | {input_id})\",\n",
    "    data=data,\n",
    ")\n",
    "model_expanded.fit(factors={\n",
    "    system_id: list(data[system_id].unique()),\n",
    "    f\"{bin_id}_bins\": list(data[f\"{bin_id}_bins\"].unique())},\n",
    "REML=False,\n",
    "summarize=False,\n",
    ")\n",
    "#print(model_expanded.ranef)\n",
    "#print(\"\")\n",
    "#print(model_expanded.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid:\n",
      "                  acquisition\n",
      "0        ExpectedImprovement\n",
      "1   ProbabilityOfImprovement\n",
      "2       UpperConfidenceBound\n",
      "3       qExpectedImprovement\n",
      "4         qKnowledgeGradient\n",
      "5  qProbabilityOfImprovement\n",
      "6              qSimpleRegret\n",
      "7      qUpperConfidenceBound\n",
      "8               randomSearch\n",
      "Coeffs:\n",
      " Intercept                                   5.759636\n",
      "acquisition[T.ProbabilityOfImprovement]     0.336997\n",
      "acquisition[T.UpperConfidenceBound]         0.118736\n",
      "acquisition[T.qExpectedImprovement]         0.061894\n",
      "acquisition[T.qKnowledgeGradient]           0.495266\n",
      "acquisition[T.qProbabilityOfImprovement]    0.523160\n",
      "acquisition[T.qSimpleRegret]                0.096439\n",
      "acquisition[T.qUpperConfidenceBound]        0.152831\n",
      "acquisition[T.randomSearch]                 0.892227\n",
      "dtype: float64\n",
      "Matrix:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "                 acquisition     means        SE\n",
      "0        ExpectedImprovement  5.759636  4.373900\n",
      "1   ProbabilityOfImprovement  6.096633  4.374206\n",
      "2       UpperConfidenceBound  5.878372  4.374206\n",
      "3       qExpectedImprovement  5.821530  4.374206\n",
      "4         qKnowledgeGradient  6.254902  4.374206\n",
      "5  qProbabilityOfImprovement  6.282796  4.374206\n",
      "6              qSimpleRegret  5.856075  4.374206\n",
      "7      qUpperConfidenceBound  5.912468  4.374206\n",
      "8               randomSearch  6.651863  4.374206\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values for each level of system_id\n",
    "\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[input_id].unique(),\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(2, len(data[input_id].unique()) * len(data[system_id].unique())).T)\n",
    "\n",
    "grid = pd.DataFrame(grid, columns=[input_id, system_id)\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(1, len(data[system_id].unique())).T)\n",
    "grid = pd.DataFrame(grid, columns=[ system_id])\n",
    "print(\"Grid:\\n\",grid)\n",
    "betas = diffModelFit.fe_params\n",
    "print(\"Coeffs:\\n\",betas)\n",
    "mat = dmatrix(f\"C({system_id})\", grid, return_type=\"matrix\")\n",
    "print(\"Matrix:\\n\",mat)\n",
    "emmeans = grid.copy()\n",
    "emmeans[\"means\"] = mat @ betas\n",
    "#print(emmeans)\n",
    "vcov = diffModelFit.cov_params()\n",
    "# print(vcov)\n",
    "\n",
    "vcov = vcov[~vcov.index.str.contains(\"Var|Cor\")]\n",
    "vcov = vcov.loc[:, ~vcov.columns.str.contains(\"Var|Cor\")]\n",
    "#print(vcov)\n",
    "emmeans[\"SE\"] = np.sqrt(np.diagonal(mat @ vcov) @ mat.T)\n",
    "print(emmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.053999\n",
      "1    0.054003\n",
      "2    0.054003\n",
      "3    0.054003\n",
      "4    0.054003\n",
      "5    0.054003\n",
      "6    0.054003\n",
      "7    0.054003\n",
      "8    0.054003\n",
      "Name: SE, dtype: float64\n",
      "36\n",
      "[0.1950384500081659, 0.03517582347057269, 0.17275811008774866, 0.17275811008774866, 0.17275811008774866, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.07080627745719625, 0.19315623833882523, 0.19315623833882523, 0.19315623833882523, 0.3669918180963192, 0.3016547026095453, 0.3016547026095453, 0.3016547026095453, 0.3016547026095453, 0.2992726887748903, 0.08287821755113056, 0.08287821755113056, 0.33537157015466157, 0.33537157015466157, 0.33537157015466157, 0.33537157015466157, 0.33537157015466157, 0.33537157015466157, 0.33537157015466157, 0.1950384500081659, 0.1950384500081659, 0.1950384500081659]\n",
      "-0.3369966713463821: q=0.9433244880176012, p=0.17275811008774866\n",
      "-0.118735837727308: q=7.548340606725078, p=0.17275811008774866\n",
      "-0.061893947976246366: q=7.973469615391716, p=0.17275811008774866\n",
      "-0.4952660582377595: q=1.4698189068446912, p=0.07080627745719625\n",
      "-0.523159866868661: q=2.32929889632547, p=0.07080627745719625\n",
      "-0.09643860210385125: q=13.598408557923458, p=0.07080627745719625\n",
      "-0.15283129669756512: q=3.3265092284470947, p=0.07080627745719625\n",
      "-0.892226590674654: q=4.192835392807325, p=0.07080627745719625\n",
      "0.2182608336190741: q=2.83730973456679, p=0.07080627745719625\n",
      "0.27510272337013575: q=3.6663409739802346, p=0.07080627745719625\n",
      "-0.15826938689137737: q=2.806860984499456, p=0.07080627745719625\n",
      "-0.1861631955222789: q=8.46224867709853, p=0.07080627745719625\n",
      "0.24055806924253087: q=0.8663261643602301, p=0.19315623833882523\n",
      "0.184165374648817: q=5.738689954347246, p=0.19315623833882523\n",
      "-0.5552299193282719: q=6.1638189630138855, p=0.19315623833882523\n",
      "0.056841889751061636: q=0.5196482439476385, p=0.3016547026095453\n",
      "-0.3765302205104515: q=11.788757905545626, p=0.3016547026095453\n",
      "-0.404424029141353: q=6.605016118707477, p=0.3016547026095453\n",
      "0.022297235623456757: q=7.030145127374115, p=0.3016547026095453\n",
      "-0.03409545897025712: q=0.5264944188270901, p=0.2992726887748903\n",
      "-0.773490752947346: q=1.3859744083078687, p=0.08287821755113056\n",
      "-0.4333721102615131: q=0.42512900866663855, p=0.33537157015466157\n",
      "-0.46126591889241464: q=6.078521699880386, p=0.33537157015466157\n",
      "-0.03454465412760488: q=5.219041710399608, p=0.33537157015466157\n",
      "-0.09093734872131876: q=6.050067951198378, p=0.33537157015466157\n",
      "-0.8303326426984077: q=6.503650708547025, p=0.33537157015466157\n",
      "-0.027893808630901518: q=5.62493894253174, p=0.33537157015466157\n",
      "0.39882745613390824: q=0.8594799894807786, p=0.1950384500081659\n",
      "0.34243476154019437: q=12.128589651078764, p=0.1950384500081659\n",
      "-0.39696053243689455: q=11.269109661597987, p=0.1950384500081659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amega\\Git\\significance_analysis\\.venv_3_10_0\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\Amega\\Git\\significance_analysis\\.venv_3_10_0\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m c\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00memmeans\u001b[39m.\u001b[39miloc[i][\u001b[39m\"\u001b[39m\u001b[39mmeans\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m \u001b[39m\u001b[39m-\u001b[39memmeans\u001b[39m.\u001b[39miloc[j][\u001b[39m\"\u001b[39m\u001b[39mmeans\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: q=\u001b[39m\u001b[39m{\u001b[39;00mq_stats[c]\u001b[39m}\u001b[39;00m\u001b[39m, p=\u001b[39m\u001b[39m{\u001b[39;00mp_values[c]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "grid[input_id]=data[input_id].unique()[0]\n",
    "#print(\"Grid:\\n\",grid)\n",
    "predicted_values = diffModelFit.predict(grid)\n",
    "#print(\"Predicted values:\\n\",predicted_values)\n",
    "#print(pd.DataFrame(predicted_values, columns=[\"pred\"]))\n",
    "# Perform Tukey's HSD test\n",
    "\n",
    "means=emmeans[\"means\"]\n",
    "standard_errors=emmeans[\"SE\"]\n",
    "sample_sizes=20\n",
    "group_labels=data[system_id].unique()\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.stats.libqsturng as tukey\n",
    "tr=pairwise_tukeyhsd(means,  group_labels, alpha=0.05)#pairwise_tukeyhsd(means, group_labels)\n",
    "#print(tr)\n",
    "\n",
    "tukey_results = MultiComparison(predicted_values, grid[system_id]).tukeyhsd(\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "# calculate the standard deviation for each pair of groups\n",
    "#print(tukey_results.std_pairs)\n",
    "#print(tukey_results.summary())\n",
    "#print(\"tukey end\")\n",
    "\n",
    "import statsmodels\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "# Calculate the standard errors for each group\n",
    "SE = emmeans[\"SE\"]\n",
    "\n",
    "n=len(emmeans[system_id])\n",
    "# Calculate the pooled standard deviation\n",
    "SD = SE/(n**2)\n",
    "MSE=SD\n",
    "print(MSE)\n",
    "# Calculate the q-statistic for each pairwise comparison\n",
    "q_stats = []\n",
    "for i in range(n):\n",
    "    for j in range(i,n):\n",
    "        if i != j:\n",
    "            d = float(emmeans.iloc[i][\"means\"]) - float(emmeans.iloc[j][\"means\"])\n",
    "            q = np.sqrt(2) * abs(d) / s\n",
    "            q_stats.append(q)\n",
    "\n",
    "# Calculate the critical value\n",
    "alpha = 0.05\n",
    "df = 179996\n",
    "critical_value = t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Compare the q-statistics to the critical value\n",
    "p_values = []\n",
    "for q in q_stats:\n",
    "    if q <= critical_value:\n",
    "        p = 1 - t.cdf(q, df)\n",
    "        p_values.append(p)\n",
    "    else:\n",
    "        p_values.append(p)\n",
    "        #p_values.append(np.nan)\n",
    "print(len(p_values))\n",
    "print(p_values)\n",
    "# Print the results in a pairwise manner\n",
    "c=0\n",
    "for i in range(number_of_samples):\n",
    "    for j in range(i,number_of_samples):\n",
    "        c+=1\n",
    "        if i != j:\n",
    "            print(f'{emmeans.iloc[i][\"means\"] -emmeans.iloc[j][\"means\"]}: q={q_stats[c]}, p={p_values[c]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
