{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the mixed effects model\n",
    "from patsy import dmatrix\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_rows\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 5000)\n",
    "pd.set_option(\"display.width\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Mixed Linear Model Regression Results\n",
      "===================================================================================\n",
      "Model:                     MixedLM         Dependent Variable:         mean        \n",
      "No. Observations:          180000          Method:                     ML          \n",
      "No. Groups:                4               Scale:                      53.4669     \n",
      "Min. group size:           45000           Log-Likelihood:             -613546.8042\n",
      "Max. group size:           45000           Converged:                  Yes         \n",
      "Mean group size:           45000.0                                                 \n",
      "-----------------------------------------------------------------------------------\n",
      "                                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept                                 5.760    4.374  1.317 0.188 -2.813 14.332\n",
      "acquisition[T.ProbabilityOfImprovement]   0.337    0.073  4.609 0.000  0.194  0.480\n",
      "acquisition[T.UpperConfidenceBound]       0.119    0.073  1.624 0.104 -0.025  0.262\n",
      "acquisition[T.qExpectedImprovement]       0.062    0.073  0.846 0.397 -0.081  0.205\n",
      "acquisition[T.qKnowledgeGradient]         0.495    0.073  6.773 0.000  0.352  0.639\n",
      "acquisition[T.qProbabilityOfImprovement]  0.523    0.073  7.155 0.000  0.380  0.666\n",
      "acquisition[T.qSimpleRegret]              0.096    0.073  1.319 0.187 -0.047  0.240\n",
      "acquisition[T.qUpperConfidenceBound]      0.153    0.073  2.090 0.037  0.010  0.296\n",
      "acquisition[T.randomSearch]               0.892    0.073 12.202 0.000  0.749  1.036\n",
      "benchmark Var                            76.513    6.062                           \n",
      "===================================================================================\n",
      "\n",
      "{'Branin': benchmark   -2.259813\n",
      "dtype: float64, 'Hartmann6': benchmark   -8.186249\n",
      "dtype: float64, 'Jahs_Bench': benchmark    16.499738\n",
      "dtype: float64, 'NN_HPO_Bench': benchmark   -6.053677\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset_copy_DELETEAFTER.csv\")\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "bins=[0,15,30,49]\n",
    "\n",
    "\n",
    "differentMeans_model = mixedlm(formula=f\"{metric} ~ {system_id}\", data=data, groups=input_id)\n",
    "diffModelFit = differentMeans_model.fit( reml=False)\n",
    "print(diffModelFit.summary())\n",
    "print(diffModelFit.random_effects)\n",
    "\n",
    "bins_set = set(bins)\n",
    "bins_set.add(data[bin_id].min())\n",
    "bins_set.add(data[bin_id].max())\n",
    "bins = sorted(list(bins_set))\n",
    "\n",
    "bin_labels = [f\"{bins[i]}_{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "\n",
    "data[f\"{bin_id}_bins\"] = pd.cut(\n",
    "    data[bin_id], bins=bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# New model \"expanded\": Divides into system AND bin-classes (Term system:bin_id allows for Cartesian Product, i.e. different Mean for each system and bin-class)\n",
    "model_expanded = Lmer(\n",
    "    f\"{metric} ~  {system_id} + {bin_id}_bins + {system_id}:{bin_id}_bins + (1 | {input_id})\",\n",
    "    data=data,\n",
    ")\n",
    "model_expanded.fit(factors={\n",
    "    system_id: list(data[system_id].unique()),\n",
    "    f\"{bin_id}_bins\": list(data[f\"{bin_id}_bins\"].unique())},\n",
    "REML=False,\n",
    "summarize=False,\n",
    ")\n",
    "#print(model_expanded.ranef)\n",
    "#print(\"\")\n",
    "#print(model_expanded.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid:\n",
      "                  acquisition\n",
      "0        ExpectedImprovement\n",
      "1   ProbabilityOfImprovement\n",
      "2       UpperConfidenceBound\n",
      "3       qExpectedImprovement\n",
      "4         qKnowledgeGradient\n",
      "5  qProbabilityOfImprovement\n",
      "6              qSimpleRegret\n",
      "7      qUpperConfidenceBound\n",
      "8               randomSearch\n",
      "Coeffs:\n",
      " Intercept                                   5.759636\n",
      "acquisition[T.ProbabilityOfImprovement]     0.336997\n",
      "acquisition[T.UpperConfidenceBound]         0.118736\n",
      "acquisition[T.qExpectedImprovement]         0.061894\n",
      "acquisition[T.qKnowledgeGradient]           0.495266\n",
      "acquisition[T.qProbabilityOfImprovement]    0.523160\n",
      "acquisition[T.qSimpleRegret]                0.096439\n",
      "acquisition[T.qUpperConfidenceBound]        0.152831\n",
      "acquisition[T.randomSearch]                 0.892227\n",
      "dtype: float64\n",
      "Matrix:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "                 acquisition     means        SE\n",
      "0        ExpectedImprovement  5.759636  4.373900\n",
      "1   ProbabilityOfImprovement  6.096633  4.374206\n",
      "2       UpperConfidenceBound  5.878372  4.374206\n",
      "3       qExpectedImprovement  5.821530  4.374206\n",
      "4         qKnowledgeGradient  6.254902  4.374206\n",
      "5  qProbabilityOfImprovement  6.282796  4.374206\n",
      "6              qSimpleRegret  5.856075  4.374206\n",
      "7      qUpperConfidenceBound  5.912468  4.374206\n",
      "8               randomSearch  6.651863  4.374206\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values for each level of system_id\n",
    "\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[input_id].unique(),\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(2, len(data[input_id].unique()) * len(data[system_id].unique())).T)\n",
    "\n",
    "grid = pd.DataFrame(grid, columns=[input_id, system_id)\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(1, len(data[system_id].unique())).T)\n",
    "grid = pd.DataFrame(grid, columns=[ system_id])\n",
    "print(\"Grid:\\n\",grid)\n",
    "betas = diffModelFit.fe_params\n",
    "print(\"Coeffs:\\n\",betas)\n",
    "mat = dmatrix(f\"C({system_id})\", grid, return_type=\"matrix\")\n",
    "print(\"Matrix:\\n\",mat)\n",
    "emmeans = grid.copy()\n",
    "emmeans[\"means\"] = mat @ betas\n",
    "#print(emmeans)\n",
    "vcov = diffModelFit.cov_params()\n",
    "# print(vcov)\n",
    "\n",
    "vcov = vcov[~vcov.index.str.contains(\"Var|Cor\")]\n",
    "vcov = vcov.loc[:, ~vcov.columns.str.contains(\"Var|Cor\")]\n",
    "#print(vcov)\n",
    "emmeans[\"SE\"] = np.sqrt(np.diagonal(mat @ vcov) @ mat.T)\n",
    "print(emmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group A - Group B: q=[0.9097176522946842, 1.8194353045893683, 0.9097176522946842, 0.9097176522946842, 1.8194353045893683, 0.9097176522946842], p=[0.22949910959977027, 0.10522898302413852, 0.22949910959977027, 0.22949910959977027, 0.10522898302413852, 0.22949910959977027]\n",
      "Group A - Group C: q=[0.9097176522946842, 1.8194353045893683, 0.9097176522946842, 0.9097176522946842, 1.8194353045893683, 0.9097176522946842], p=[0.22949910959977027, 0.10522898302413852, 0.22949910959977027, 0.22949910959977027, 0.10522898302413852, 0.22949910959977027]\n",
      "Group B - Group A: q=[0.9097176522946842, 1.8194353045893683, 0.9097176522946842, 0.9097176522946842, 1.8194353045893683, 0.9097176522946842], p=[0.22949910959977027, 0.10522898302413852, 0.22949910959977027, 0.22949910959977027, 0.10522898302413852, 0.22949910959977027]\n",
      "Group B - Group C: q=[0.9097176522946842, 1.8194353045893683, 0.9097176522946842, 0.9097176522946842, 1.8194353045893683, 0.9097176522946842], p=[0.22949910959977027, 0.10522898302413852, 0.22949910959977027, 0.22949910959977027, 0.10522898302413852, 0.22949910959977027]\n",
      "Group C - Group A: q=[0.9097176522946842, 1.8194353045893683, 0.9097176522946842, 0.9097176522946842, 1.8194353045893683, 0.9097176522946842], p=[0.22949910959977027, 0.10522898302413852, 0.22949910959977027, 0.22949910959977027, 0.10522898302413852, 0.22949910959977027]\n",
      "Group C - Group B: q=[0.9097176522946842, 1.8194353045893683, 0.9097176522946842, 0.9097176522946842, 1.8194353045893683, 0.9097176522946842], p=[0.22949910959977027, 0.10522898302413852, 0.22949910959977027, 0.22949910959977027, 0.10522898302413852, 0.22949910959977027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amega\\Git\\significance_analysis\\.venv_3_10_0\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\Amega\\Git\\significance_analysis\\.venv_3_10_0\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "grid[input_id]=data[input_id].unique()[0]\n",
    "#print(\"Grid:\\n\",grid)\n",
    "predicted_values = diffModelFit.predict(grid)\n",
    "#print(\"Predicted values:\\n\",predicted_values)\n",
    "#print(pd.DataFrame(predicted_values, columns=[\"pred\"]))\n",
    "# Perform Tukey's HSD test\n",
    "\n",
    "means=emmeans[\"means\"]\n",
    "standard_errors=emmeans[\"SE\"]\n",
    "sample_sizes=20\n",
    "group_labels=data[system_id].unique()\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.stats.libqsturng as tukey\n",
    "tr=pairwise_tukeyhsd(means,  group_labels, alpha=0.05)#pairwise_tukeyhsd(means, group_labels)\n",
    "#print(tr)\n",
    "\n",
    "tukey_results = MultiComparison(predicted_values, grid[system_id]).tukeyhsd(\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "# calculate the standard deviation for each pair of groups\n",
    "#print(tukey_results.std_pairs)\n",
    "#print(tukey_results.summary())\n",
    "#print(\"tukey end\")\n",
    "\n",
    "import statsmodels\n",
    "from scipy.stats import t\n",
    "# Create a small table with the group means and standard errors\n",
    "table = np.array([\n",
    "    ['Group A', 100, 10],\n",
    "    ['Group B', 110, 15],\n",
    "    ['Group C', 120, 20],\n",
    "])\n",
    "\n",
    "# Calculate the standard errors for each group\n",
    "ses = np.array([10, 15, 20])\n",
    "\n",
    "# Calculate the pooled standard deviation\n",
    "s = np.sqrt(sum(ses**2) / 3)\n",
    "\n",
    "# Calculate the q-statistic for each pairwise comparison\n",
    "q_stats = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i != j:\n",
    "            d = float(table[i, 1]) - float(table[j, 1])\n",
    "            q = np.sqrt(2) * abs(d) / s\n",
    "            q_stats.append(q)\n",
    "\n",
    "# Calculate the critical value\n",
    "alpha = 0.05\n",
    "df = 2\n",
    "critical_value = np.round(t.ppf(1 - alpha / 2, df), 3)\n",
    "\n",
    "# Compare the q-statistics to the critical value\n",
    "p_values = []\n",
    "for q in q_stats:\n",
    "    if q <= critical_value:\n",
    "        p = 1 - t.cdf(q, df)\n",
    "        p_values.append(p)\n",
    "    else:\n",
    "        p_values.append(np.nan)\n",
    "\n",
    "# Print the results in a pairwise manner\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i != j:\n",
    "            print(f'{table[i, 0]} - {table[j, 0]}: q={q_stats}, p={p_values}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
