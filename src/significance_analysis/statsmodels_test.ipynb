{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the mixed effects model\n",
    "from patsy import dmatrix\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_rows\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 5000)\n",
    "pd.set_option(\"display.width\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Mixed Linear Model Regression Results\n",
      "===================================================================================\n",
      "Model:                     MixedLM         Dependent Variable:         mean        \n",
      "No. Observations:          180000          Method:                     ML          \n",
      "No. Groups:                4               Scale:                      53.4669     \n",
      "Min. group size:           45000           Log-Likelihood:             -613546.8042\n",
      "Max. group size:           45000           Converged:                  Yes         \n",
      "Mean group size:           45000.0                                                 \n",
      "-----------------------------------------------------------------------------------\n",
      "                                         Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept                                 5.760    4.374  1.317 0.188 -2.813 14.332\n",
      "acquisition[T.ProbabilityOfImprovement]   0.337    0.073  4.609 0.000  0.194  0.480\n",
      "acquisition[T.UpperConfidenceBound]       0.119    0.073  1.624 0.104 -0.025  0.262\n",
      "acquisition[T.qExpectedImprovement]       0.062    0.073  0.846 0.397 -0.081  0.205\n",
      "acquisition[T.qKnowledgeGradient]         0.495    0.073  6.773 0.000  0.352  0.639\n",
      "acquisition[T.qProbabilityOfImprovement]  0.523    0.073  7.155 0.000  0.380  0.666\n",
      "acquisition[T.qSimpleRegret]              0.096    0.073  1.319 0.187 -0.047  0.240\n",
      "acquisition[T.qUpperConfidenceBound]      0.153    0.073  2.090 0.037  0.010  0.296\n",
      "acquisition[T.randomSearch]               0.892    0.073 12.202 0.000  0.749  1.036\n",
      "benchmark Var                            76.513    6.062                           \n",
      "===================================================================================\n",
      "\n",
      "{'Branin': benchmark   -2.259813\n",
      "dtype: float64, 'Hartmann6': benchmark   -8.186249\n",
      "dtype: float64, 'Jahs_Bench': benchmark    16.499738\n",
      "dtype: float64, 'NN_HPO_Bench': benchmark   -6.053677\n",
      "dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset_copy_DELETEAFTER.csv\")\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "bins=[0,15,30,49]\n",
    "\n",
    "\n",
    "differentMeans_model = mixedlm(formula=f\"{metric} ~ {system_id}\", data=data, groups=input_id)\n",
    "diffModelFit = differentMeans_model.fit( reml=False)\n",
    "print(diffModelFit.summary())\n",
    "print(diffModelFit.random_effects)\n",
    "\n",
    "bins_set = set(bins)\n",
    "bins_set.add(data[bin_id].min())\n",
    "bins_set.add(data[bin_id].max())\n",
    "bins = sorted(list(bins_set))\n",
    "\n",
    "bin_labels = [f\"{bins[i]}_{bins[i+1]}\" for i in range(len(bins) - 1)]\n",
    "\n",
    "\n",
    "data[f\"{bin_id}_bins\"] = pd.cut(\n",
    "    data[bin_id], bins=bins, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# New model \"expanded\": Divides into system AND bin-classes (Term system:bin_id allows for Cartesian Product, i.e. different Mean for each system and bin-class)\n",
    "model_expanded = Lmer(\n",
    "    f\"{metric} ~  {system_id} + {bin_id}_bins + {system_id}:{bin_id}_bins + (1 | {input_id})\",\n",
    "    data=data,\n",
    ")\n",
    "model_expanded.fit(factors={\n",
    "    system_id: list(data[system_id].unique()),\n",
    "    f\"{bin_id}_bins\": list(data[f\"{bin_id}_bins\"].unique())},\n",
    "REML=False,\n",
    "summarize=False,\n",
    ")\n",
    "#print(model_expanded.ranef)\n",
    "#print(\"\")\n",
    "#print(model_expanded.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid:\n",
      "                  acquisition\n",
      "0        ExpectedImprovement\n",
      "1   ProbabilityOfImprovement\n",
      "2       UpperConfidenceBound\n",
      "3       qExpectedImprovement\n",
      "4         qKnowledgeGradient\n",
      "5  qProbabilityOfImprovement\n",
      "6              qSimpleRegret\n",
      "7      qUpperConfidenceBound\n",
      "8               randomSearch\n",
      "Coeffs:\n",
      " Intercept                                   5.759636\n",
      "acquisition[T.ProbabilityOfImprovement]     0.336997\n",
      "acquisition[T.UpperConfidenceBound]         0.118736\n",
      "acquisition[T.qExpectedImprovement]         0.061894\n",
      "acquisition[T.qKnowledgeGradient]           0.495266\n",
      "acquisition[T.qProbabilityOfImprovement]    0.523160\n",
      "acquisition[T.qSimpleRegret]                0.096439\n",
      "acquisition[T.qUpperConfidenceBound]        0.152831\n",
      "acquisition[T.randomSearch]                 0.892227\n",
      "dtype: float64\n",
      "Matrix:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "                 acquisition     means        SE\n",
      "0        ExpectedImprovement  5.759636  4.373900\n",
      "1   ProbabilityOfImprovement  6.096633  4.374206\n",
      "2       UpperConfidenceBound  5.878372  4.374206\n",
      "3       qExpectedImprovement  5.821530  4.374206\n",
      "4         qKnowledgeGradient  6.254902  4.374206\n",
      "5  qProbabilityOfImprovement  6.282796  4.374206\n",
      "6              qSimpleRegret  5.856075  4.374206\n",
      "7      qUpperConfidenceBound  5.912468  4.374206\n",
      "8               randomSearch  6.651863  4.374206\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values for each level of system_id\n",
    "\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[input_id].unique(),\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(2, len(data[input_id].unique()) * len(data[system_id].unique())).T)\n",
    "\n",
    "grid = pd.DataFrame(grid, columns=[input_id, system_id)\"\"\"\n",
    "grid = (\n",
    "    np.array(\n",
    "        np.meshgrid(\n",
    "            data[system_id].unique(),\n",
    "        )\n",
    "    )\n",
    "    .reshape(1, len(data[system_id].unique())).T)\n",
    "grid = pd.DataFrame(grid, columns=[ system_id])\n",
    "print(\"Grid:\\n\",grid)\n",
    "betas = diffModelFit.fe_params\n",
    "print(\"Coeffs:\\n\",betas)\n",
    "mat = dmatrix(f\"C({system_id})\", grid, return_type=\"matrix\")\n",
    "print(\"Matrix:\\n\",mat)\n",
    "emmeans = grid.copy()\n",
    "emmeans[\"means\"] = mat @ betas\n",
    "#print(emmeans)\n",
    "vcov = diffModelFit.cov_params()\n",
    "# print(vcov)\n",
    "\n",
    "vcov = vcov[~vcov.index.str.contains(\"Var|Cor\")]\n",
    "vcov = vcov.loc[:, ~vcov.columns.str.contains(\"Var|Cor\")]\n",
    "#print(vcov)\n",
    "emmeans[\"SE\"] = np.sqrt(np.diagonal(mat @ vcov) @ mat.T)\n",
    "print(emmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amega\\Desktop\\Git\\significance_analysis\\.venv3_10_1\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\Amega\\Desktop\\Git\\significance_analysis\\.venv3_10_1\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\Amega\\Desktop\\Git\\significance_analysis\\.venv3_10_1\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: RuntimeWarning: invalid value encountered in divide\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpectedImprovement - ProbabilityOfImprovement: q=5.428951969822306, p=nan\n",
      "ExpectedImprovement - UpperConfidenceBound: q=2.829973470667195, p=nan\n",
      "ExpectedImprovement - qExpectedImprovement: q=22.645021873101985, p=nan\n",
      "ExpectedImprovement - qKnowledgeGradient: q=23.920408902082784, p=nan\n",
      "ExpectedImprovement - qProbabilityOfImprovement: q=4.409456730840087, p=nan\n",
      "ExpectedImprovement - qSimpleRegret: q=6.98789670530884, p=nan\n",
      "ExpectedImprovement - qUpperConfidenceBound: q=40.79522576911844, p=nan\n",
      "ExpectedImprovement - randomSearch: q=15.40847967848804, p=nan\n",
      "ProbabilityOfImprovement - ExpectedImprovement: q=9.979527708665733, p=nan\n",
      "ProbabilityOfImprovement - UpperConfidenceBound: q=7.236542194613947, p=nan\n",
      "ProbabilityOfImprovement - qExpectedImprovement: q=8.51192922359474, p=nan\n",
      "ProbabilityOfImprovement - qKnowledgeGradient: q=10.999022947647953, p=nan\n",
      "ProbabilityOfImprovement - qProbabilityOfImprovement: q=8.420582973179199, p=nan\n",
      "ProbabilityOfImprovement - qSimpleRegret: q=25.386746090630396, p=nan\n",
      "ProbabilityOfImprovement - qUpperConfidenceBound: q=5.428951969822306, p=nan\n",
      "ProbabilityOfImprovement - randomSearch: q=9.979527708665733, p=nan\n",
      "UpperConfidenceBound - ExpectedImprovement: q=2.5989784991551113, p=nan\n",
      "UpperConfidenceBound - ProbabilityOfImprovement: q=17.21606990327968, p=nan\n",
      "UpperConfidenceBound - qExpectedImprovement: q=1.019495238982219, p=nan\n",
      "UpperConfidenceBound - qKnowledgeGradient: q=1.5589447354865342, p=nan\n",
      "UpperConfidenceBound - qProbabilityOfImprovement: q=35.36627379929613, p=nan\n",
      "UpperConfidenceBound - qSimpleRegret: q=2.829973470667195, p=nan\n",
      "UpperConfidenceBound - qUpperConfidenceBound: q=12.578506207820846, p=nan\n",
      "UpperConfidenceBound - randomSearch: q=2.5989784991551113, p=nan\n",
      "qExpectedImprovement - ExpectedImprovement: q=19.81504840243479, p=nan\n",
      "qExpectedImprovement - ProbabilityOfImprovement: q=21.090435431415585, p=nan\n",
      "qExpectedImprovement - UpperConfidenceBound: q=1.5794832601728923, p=nan\n",
      "qExpectedImprovement - qKnowledgeGradient: q=37.96525229845124, p=nan\n",
      "qExpectedImprovement - qProbabilityOfImprovement: q=22.645021873101985, p=nan\n",
      "qExpectedImprovement - qSimpleRegret: q=7.236542194613947, p=nan\n",
      "qExpectedImprovement - qUpperConfidenceBound: q=17.21606990327968, p=nan\n",
      "qExpectedImprovement - randomSearch: q=19.81504840243479, p=nan\n",
      "qKnowledgeGradient - ExpectedImprovement: q=1.2753870289807936, p=nan\n",
      "qKnowledgeGradient - ProbabilityOfImprovement: q=18.2355651422619, p=nan\n",
      "qKnowledgeGradient - UpperConfidenceBound: q=15.657125167793147, p=nan\n",
      "qKnowledgeGradient - qExpectedImprovement: q=18.15020389601645, p=nan\n",
      "qKnowledgeGradient - qProbabilityOfImprovement: q=8.51192922359474, p=nan\n",
      "qKnowledgeGradient - qSimpleRegret: q=18.491456932260473, p=nan\n",
      "qKnowledgeGradient - qUpperConfidenceBound: q=21.090435431415585, p=nan\n",
      "qKnowledgeGradient - randomSearch: q=1.2753870289807936, p=nan\n",
      "qProbabilityOfImprovement - ExpectedImprovement: q=19.510952171242693, p=nan\n",
      "qProbabilityOfImprovement - ProbabilityOfImprovement: q=16.93251219677394, p=nan\n",
      "qProbabilityOfImprovement - UpperConfidenceBound: q=16.874816867035655, p=nan\n",
      "qProbabilityOfImprovement - qExpectedImprovement: q=4.409456730840087, p=nan\n",
      "qProbabilityOfImprovement - qKnowledgeGradient: q=10.999022947647953, p=nan\n",
      "qProbabilityOfImprovement - qSimpleRegret: q=1.5794832601728923, p=nan\n",
      "qProbabilityOfImprovement - qUpperConfidenceBound: q=18.2355651422619, p=nan\n",
      "qProbabilityOfImprovement - randomSearch: q=19.510952171242693, p=nan\n",
      "qSimpleRegret - ExpectedImprovement: q=2.578439974468753, p=nan\n",
      "qSimpleRegret - ProbabilityOfImprovement: q=36.38576903827835, p=nan\n",
      "qSimpleRegret - UpperConfidenceBound: q=6.98789670530884, p=nan\n",
      "qSimpleRegret - qExpectedImprovement: q=8.420582973179199, p=nan\n",
      "qSimpleRegret - qKnowledgeGradient: q=1.5589447354865342, p=nan\n",
      "qSimpleRegret - qProbabilityOfImprovement: q=4.157923234641645, p=nan\n",
      "qSimpleRegret - qUpperConfidenceBound: q=16.93251219677394, p=nan\n",
      "qSimpleRegret - randomSearch: q=2.578439974468753, p=nan\n",
      "qUpperConfidenceBound - ExpectedImprovement: q=33.8073290638096, p=nan\n",
      "qUpperConfidenceBound - ProbabilityOfImprovement: q=40.79522576911844, p=nan\n",
      "qUpperConfidenceBound - UpperConfidenceBound: q=25.386746090630396, p=nan\n",
      "qUpperConfidenceBound - qExpectedImprovement: q=35.36627379929613, p=nan\n",
      "qUpperConfidenceBound - qKnowledgeGradient: q=37.96525229845124, p=nan\n",
      "qUpperConfidenceBound - qProbabilityOfImprovement: q=18.15020389601645, p=nan\n",
      "qUpperConfidenceBound - qSimpleRegret: q=16.874816867035655, p=nan\n",
      "qUpperConfidenceBound - randomSearch: q=33.8073290638096, p=nan\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_samples):\n\u001b[0;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[1;32m---> 69\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00memmeans\u001b[39m.\u001b[39miloc[i][system_id]\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00memmeans\u001b[39m.\u001b[39miloc[j][system_id]\u001b[39m}\u001b[39;00m\u001b[39m: q=\u001b[39m\u001b[39m{\u001b[39;00mq_stats[number_of_samples\u001b[39m*\u001b[39;49mi\u001b[39m+\u001b[39;49mj]\u001b[39m}\u001b[39;00m\u001b[39m, p=\u001b[39m\u001b[39m{\u001b[39;00mp_values[number_of_samples\u001b[39m*\u001b[39mi\u001b[39m+\u001b[39mj]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "grid[input_id]=data[input_id].unique()[0]\n",
    "#print(\"Grid:\\n\",grid)\n",
    "predicted_values = diffModelFit.predict(grid)\n",
    "#print(\"Predicted values:\\n\",predicted_values)\n",
    "#print(pd.DataFrame(predicted_values, columns=[\"pred\"]))\n",
    "# Perform Tukey's HSD test\n",
    "\n",
    "means=emmeans[\"means\"]\n",
    "standard_errors=emmeans[\"SE\"]\n",
    "sample_sizes=20\n",
    "group_labels=data[system_id].unique()\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.stats.libqsturng as tukey\n",
    "tr=pairwise_tukeyhsd(means,  group_labels, alpha=0.05)#pairwise_tukeyhsd(means, group_labels)\n",
    "#print(tr)\n",
    "\n",
    "tukey_results = MultiComparison(predicted_values, grid[system_id]).tukeyhsd(\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "# calculate the standard deviation for each pair of groups\n",
    "#print(tukey_results.std_pairs)\n",
    "#print(tukey_results.summary())\n",
    "#print(\"tukey end\")\n",
    "\n",
    "import statsmodels\n",
    "from scipy.stats import t\n",
    "# Create a small table with the group means and standard errors\n",
    "table = np.array([\n",
    "    ['Group A', 100, 10],\n",
    "    ['Group B', 110, 15],\n",
    "    ['Group C', 120, 20],\n",
    "])\n",
    "\n",
    "# Calculate the standard errors for each group\n",
    "ses = emmeans[\"SE\"]\n",
    "\n",
    "number_of_samples=len(emmeans[system_id])\n",
    "# Calculate the pooled standard deviation\n",
    "s = np.sqrt(sum(ses**2) / 180000)\n",
    "\n",
    "# Calculate the q-statistic for each pairwise comparison\n",
    "q_stats = []\n",
    "for i in range(number_of_samples):\n",
    "    for j in range(number_of_samples):\n",
    "        if i != j:\n",
    "            d = float(emmeans.iloc[i][\"means\"]) - float(emmeans.iloc[j][\"means\"])\n",
    "            q = np.sqrt(2) * abs(d) / s\n",
    "            q_stats.append(q)\n",
    "\n",
    "# Calculate the critical value\n",
    "alpha = 0.05\n",
    "df = 179996\n",
    "critical_value = np.round(t.ppf(1 - alpha / 2, df), df+1)\n",
    "\n",
    "# Compare the q-statistics to the critical value\n",
    "p_values = []\n",
    "for q in q_stats:\n",
    "    if q <= critical_value:\n",
    "        p = 1 - t.cdf(q, df)\n",
    "        p_values.append(p)\n",
    "    else:\n",
    "        p_values.append(np.nan)\n",
    "\n",
    "# Print the results in a pairwise manner\n",
    "for i in range(number_of_samples):\n",
    "    for j in range(number_of_samples):\n",
    "        if i != j:\n",
    "            print(f'{emmeans.iloc[i][system_id]} - {emmeans.iloc[j][system_id]}: q={q_stats[number_of_samples*i+j]}, p={p_values[number_of_samples*i+j]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
