{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                   seed-0    seed-1    seed-2    seed-3    seed-4    seed-5    seed-6    seed-7    seed-8    seed-9   seed-10   seed-11   seed-12   seed-13   seed-14   seed-15   seed-16   seed-17   seed-18   seed-19   seed-20   seed-21   seed-22   seed-23   seed-24   seed-25   seed-26   seed-27   seed-28   seed-29   seed-30   seed-31   seed-32   seed-33   seed-34   seed-35   seed-36   seed-37   seed-38   seed-39   seed-40   seed-41   seed-42   seed-43   seed-44   seed-45   seed-46   seed-47   seed-48   seed-49\n",
      "benchmark      prior algorithm                                    used_fidelity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "lcbench-167190 bad   pb_mutation_dynamic_linear-default-at-target 1.000000       0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580  0.521580\n",
      "                                                                  1.019231       0.445254  0.461218  0.509513  0.508200  0.446627  0.466726  0.513062  0.461038  0.508796  0.464837  0.484489  0.429274  0.456871  0.436047  0.475566  0.448518  0.479997  0.462406  0.458515  0.494119  0.446536  0.465185  0.484702  0.498725  0.445140  0.521580  0.510893  0.457890  0.481118  0.495387  0.508786  0.504330  0.507891  0.493120  0.511081  0.507216  0.496625  0.432121  0.450262  0.497408  0.521580  0.514443  0.462840  0.474355  0.459538  0.512165  0.512982  0.521580  0.507123  0.505890\n",
      "                                                                  1.038462       0.445254  0.442629  0.461113  0.508200  0.446627  0.466726  0.506023  0.443088  0.443944  0.464837  0.456487  0.429274  0.456871  0.436047  0.458248  0.448518  0.445001  0.462406  0.458515  0.453206  0.444746  0.465185  0.484702  0.498725  0.445140  0.474206  0.504118  0.457890  0.481118  0.458957  0.508786  0.498713  0.454083  0.493120  0.496839  0.498840  0.496625  0.432121  0.450262  0.459040  0.504634  0.510723  0.462840  0.458486  0.459538  0.461272  0.512982  0.479749  0.467347  0.505890\n",
      "                                                                  1.057692       0.443823  0.431065  0.461113  0.431991  0.446627  0.466726  0.476165  0.443088  0.443944  0.436413  0.456487  0.429274  0.456871  0.436047  0.458248  0.448518  0.445001  0.462406  0.434033  0.453206  0.444746  0.465185  0.441218  0.498725  0.445140  0.474206  0.504118  0.457890  0.455815  0.458957  0.508786  0.474527  0.454083  0.493120  0.496839  0.465947  0.469817  0.432121  0.450262  0.459040  0.503086  0.510723  0.462840  0.458486  0.459494  0.461272  0.499312  0.479749  0.467347  0.456664\n",
      "                                                                  1.076923       0.443823  0.431065  0.461113  0.431991  0.446627  0.466726  0.464414  0.443088  0.443944  0.436413  0.443641  0.429274  0.456871  0.436047  0.451918  0.448518  0.445001  0.462406  0.434033  0.453206  0.444746  0.465185  0.441218  0.498725  0.445140  0.474206  0.478018  0.457890  0.455815  0.458957  0.508786  0.470805  0.454083  0.470264  0.420841  0.465947  0.469817  0.432121  0.450262  0.459040  0.503086  0.432627  0.459717  0.458486  0.459494  0.461272  0.460680  0.479749  0.467347  0.443726\n",
      "...                                                                                   ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...       ...\n",
      "lcbench-168330 at25  pb_mutation_dynamic_50-default-at-target     20.557692      0.389643  0.390303  0.401503  0.350458  0.358976  0.398832  0.310087  0.436582  0.356348  0.408356  0.394394  0.331875  0.318460  0.354632  0.397131  0.400136  0.402035  0.400515  0.414010  0.393967  0.337327  0.360593  0.348060  0.378570  0.392542  0.379228  0.390287  0.398531  0.388087  0.387151  0.383343  0.389735  0.320753  0.391016  0.374537  0.392566  0.396220  0.416236  0.384364  0.338533  0.384443  0.358633  0.395409  0.346048  0.325890  0.393372  0.390305  0.374969  0.403516  0.298454\n",
      "                                                                  21.230769      0.389643  0.390303  0.377352  0.350458  0.358976  0.398832  0.310087  0.436582  0.356348  0.408356  0.394394  0.331875  0.318460  0.354632  0.397131  0.400136  0.402035  0.400515  0.414010  0.393967  0.337327  0.360593  0.348060  0.378570  0.392542  0.379228  0.390287  0.398531  0.388087  0.387151  0.383343  0.389735  0.320753  0.391016  0.363663  0.392566  0.396220  0.416236  0.384364  0.338533  0.384443  0.358633  0.395409  0.346048  0.325890  0.393372  0.390305  0.374969  0.403516  0.298454\n",
      "                                                                  22.230769      0.389643  0.390303  0.377352  0.350458  0.358976  0.398832  0.310087  0.436582  0.356348  0.408356  0.394394  0.331875  0.318460  0.354632  0.397131  0.400136  0.402035  0.400515  0.414010  0.393967  0.337327  0.360593  0.348060  0.378570  0.392542  0.379228  0.390287  0.398531  0.388087  0.387151  0.383343  0.389735  0.320753  0.391016  0.363663  0.392566  0.388612  0.416236  0.384364  0.316684  0.384443  0.358633  0.395409  0.346048  0.325890  0.393372  0.390305  0.374969  0.403516  0.298454\n",
      "                                                                  23.230769      0.389643  0.390303  0.377352  0.350458  0.352589  0.398832  0.310087  0.404704  0.356348  0.408356  0.394394  0.331875  0.318460  0.339207  0.397131  0.395576  0.402035  0.400515  0.414010  0.393967  0.337327  0.360593  0.348060  0.378570  0.348946  0.349826  0.390287  0.398531  0.388087  0.387151  0.345084  0.389735  0.320753  0.391016  0.363663  0.392566  0.388612  0.416236  0.384364  0.316684  0.384443  0.358633  0.395409  0.346048  0.325890  0.393372  0.390305  0.374969  0.403516  0.298454\n",
      "                                                                  24.230769      0.389643  0.390303  0.377352  0.310371  0.352589  0.398832  0.310087  0.404704  0.356348  0.408356  0.394394  0.331875  0.313236  0.339207  0.397131  0.395576  0.392988  0.400515  0.414010  0.393967  0.337327  0.360593  0.348060  0.378570  0.348946  0.349826  0.390287  0.398531  0.388087  0.387151  0.335633  0.389735  0.320753  0.391016  0.363663  0.392566  0.387177  0.416236  0.384364  0.316684  0.384443  0.358633  0.395409  0.346048  0.325890  0.393372  0.389893  0.374969  0.403516  0.298454\n",
      "\n",
      "[91500 rows x 50 columns]\n",
      "              benchmark prior                                     algorithm  used_fidelity     value  seed\n",
      "0        lcbench-167190   bad  pb_mutation_dynamic_linear-default-at-target       1.000000  0.521580     0\n",
      "1        lcbench-167190   bad  pb_mutation_dynamic_linear-default-at-target       1.019231  0.445254     0\n",
      "2        lcbench-167190   bad  pb_mutation_dynamic_linear-default-at-target       1.038462  0.445254     0\n",
      "3        lcbench-167190   bad  pb_mutation_dynamic_linear-default-at-target       1.057692  0.443823     0\n",
      "4        lcbench-167190   bad  pb_mutation_dynamic_linear-default-at-target       1.076923  0.443823     0\n",
      "...                 ...   ...                                           ...            ...       ...   ...\n",
      "4574995  lcbench-168330  at25      pb_mutation_dynamic_50-default-at-target      20.557692  0.298454    49\n",
      "4574996  lcbench-168330  at25      pb_mutation_dynamic_50-default-at-target      21.230769  0.298454    49\n",
      "4574997  lcbench-168330  at25      pb_mutation_dynamic_50-default-at-target      22.230769  0.298454    49\n",
      "4574998  lcbench-168330  at25      pb_mutation_dynamic_50-default-at-target      23.230769  0.298454    49\n",
      "4574999  lcbench-168330  at25      pb_mutation_dynamic_50-default-at-target      24.230769  0.298454    49\n",
      "\n",
      "[4575000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"chained_assignment\", None)\n",
    "pd.set_option(\"display.max_rows\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 5000)\n",
    "pd.set_option(\"display.width\", 10000)\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"data_for_anton.parquet\")\n",
    "print(df)\n",
    "df_formatted=pd.DataFrame(columns=[\"benchmark\",\"prior\",\"algorithm\",\"fidelity\",\"seed\",\"score\"])\n",
    "df=df.reset_index()\n",
    "df_collection=[]\n",
    "for seed_nr in range(50):\n",
    "    partial_df=df[[\"benchmark\",\"prior\",\"algorithm\",\"used_fidelity\"]]\n",
    "    partial_df[\"value\"]=df[f\"seed-{seed_nr}\"]\n",
    "    partial_df[\"seed\"]=seed_nr\n",
    "    df_collection.append(partial_df)\n",
    "    print(f\"Seed {seed_nr+1}/50\", end=\"\\r\", flush=True)\n",
    "df_formatted=pd.concat(df_collection,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pb_mutation_dynamic_linear-default-at-target': 'pb_mutation', 'priorband_crossover_decay_linear': 'priorband_crossover', 'pb_mutation_decay_geometric_bo-no-default': 'pb_mutation', 'pb_mutation_dynamic_linear_bo': 'pb_mutation', 'pibo-no-default': 'bo', 'pb_mutation_constant_linear': 'pb_mutation', 'pb_hypersphere_dynamic_50': 'priorband_hypersphere', 'pb_mutation_constant_50': 'pb_mutation', 'priorband_hypersphere_dynamic-default-at-target': 'priorband_hypersphere', 'pb_mutation_decay_geometric-no-default': 'pb_mutation', 'bo': 'bo', 'bohb': 'bo', 'hb_inc': 'hb', 'pb_mutation_decay_geometric-default-at-target': 'pb_mutation', 'asha_hb_priorband': 'asha', 'hyperband_prior-no-default': 'hb', 'bo-10': 'bo', 'pb_mutation_decay_geometric_bo-default-at-target': 'pb_mutation', 'priorband_crossover_constant_linear': 'priorband_crossover', 'priorband_crossover_decay': 'priorband_crossover', 'pb_mutation_dynamic_linear': 'pb_mutation', 'pb_mutation_dynamic_geometric-no-default': 'pb_mutation', 'pb_hypersphere_dynamic_linear': 'priorband_hypersphere', 'priorband_crossover_dynamic-default-at-target': 'priorband_crossover', 'random_search_prior-50': 'random_search', 'hb_inc-50': 'hb', 'asha_priorband': 'asha', 'pb_mutation_dynamic_geometric_bo': 'pb_mutation', 'hyperband_prior': 'hb', 'hyperband_prior-default-at-target': 'hb', 'hyperband_prior-50': 'hb', 'random_search_prior': 'random_search', 'pb_mutation_decay_geometric': 'pb_mutation', 'pibo-default-first-10': 'bo', 'priorband_crossover_dynamic': 'priorband_crossover', 'pb_mutation_decay_linear': 'pb_mutation', 'random_search': 'random_search', 'pb_mutation_constant_geometric': 'pb_mutation', 'pb_mutation_dynamic_geometric_bo-default-at-target': 'pb_mutation', 'hyperband_prior_geom': 'hb', 'hyperband': 'hb', 'pb_mutation_dynamic_geometric-default-at-target': 'pb_mutation', 'priorband_bo': 'bo', 'priorband_hypersphere_decay': 'priorband_hypersphere', 'pb_mutation_dynamic_geometric_bo-no-default': 'pb_mutation', 'pb_mutation_dynamic_50_bo': 'pb_mutation', 'pb_mutation_decay_geometric_bo': 'pb_mutation', 'pb_mutation_decay_50': 'pb_mutation', 'pb_mutation_dynamic_50': 'pb_mutation', 'pb_hypersphere_dynamic_geometric': 'priorband_hypersphere', 'priorband_hypersphere_dynamic_linear': 'priorband_hypersphere', 'priorband_hypersphere_decay_linear': 'priorband_hypersphere', 'random_search_prior-no-default': 'random_search', 'pb_mutation_constant_geometric-default-at-target': 'pb_mutation', 'pb_mutation_dynamic_geometric': 'pb_mutation', 'pb_mutation_dynamic_50-default-at-target': 'pb_mutation'}\n",
      "58\n",
      "['pb_mutation' 'priorband_crossover' 'bo' 'priorband_hypersphere' 'hb'\n",
      " 'asha' 'random_search' 'priorband-50' 'priorband']\n"
     ]
    }
   ],
   "source": [
    "unique=list(df_formatted[\"algorithm\"].unique())\n",
    "dict={}\n",
    "for algo in df_formatted[\"algorithm\"].unique():\n",
    "    if \"pb_mutation\" in algo:\n",
    "        dict[algo]=\"pb_mutation\"\n",
    "        unique.remove(algo)\n",
    "    elif \"priorband_hypersphere\" in algo or \"pb_hypersphere\" in algo:\n",
    "        dict[algo]=\"priorband_hypersphere\"\n",
    "        unique.remove(algo)\n",
    "    elif \"priorband_crossover\" in algo or \"pb_crossover\" in algo:\n",
    "        dict[algo]=\"priorband_crossover\"\n",
    "        unique.remove(algo)\n",
    "    elif \"random_search\" in algo:\n",
    "        dict[algo]=\"random_search\"\n",
    "        unique.remove(algo)\n",
    "    elif \"bo\" in algo:\n",
    "        dict[algo]=\"bo\"\n",
    "        unique.remove(algo)\n",
    "    elif \"asha\" in algo:\n",
    "        dict[algo]=\"asha\"\n",
    "        unique.remove(algo)\n",
    "    elif \"hb\" in algo or \"hyperband\" in algo:\n",
    "        dict[algo]=\"hb\"\n",
    "        unique.remove(algo)\n",
    "print(dict)\n",
    "\n",
    "def map_values(value):\n",
    "    mapped_value = dict.get(value, value)\n",
    "    return mapped_value\n",
    "\n",
    "df_formatted[\"algorithm_family\"]=df_formatted['algorithm']\n",
    "print(len(df_formatted[\"algorithm_family\"].unique()))\n",
    "df_formatted[\"algorithm_family\"]=df_formatted['algorithm_family'].map(map_values)\n",
    "print(df_formatted[\"algorithm_family\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymer4 import Lmer\n",
    "from scipy import stats\n",
    "\n",
    "df_model=df_formatted#.loc[(df_formatted[\"algorithm_family\"]==\"pb_mutation\")|(df_formatted[\"algorithm_family\"]==\"random_search\")]\n",
    "\n",
    "def create_model(system_id:str=\"algorithm\",fidelity_type:int=0):\n",
    "    metric=\"value\"\n",
    "    input_id=\"benchmark\"\n",
    "    fidelity=\"used_fidelity\"\n",
    "    df_model[input_id]=df_model[input_id].astype(str)\n",
    "    df_model[system_id]=df_model[system_id].astype(str)\n",
    "    df_model[metric]=df_model[metric].astype(float)\n",
    "    df_model[fidelity]=df_model[fidelity].astype(float)\n",
    "\n",
    "    \n",
    "    if fidelity_type==0:\n",
    "        model = Lmer(\n",
    "            formula=f\"{metric}~{system_id} + (1|{input_id})\", data=df_model\n",
    "        )\n",
    "    elif fidelity_type== 1:\n",
    "        model = Lmer(\n",
    "            formula=f\"{metric}~{system_id} + (1|{fidelity})+ (1|{input_id})\", data=df_model\n",
    "        )\n",
    "    elif fidelity_type== 2:\n",
    "        model = Lmer(\n",
    "            formula=f\"{metric}~{system_id} + {fidelity}+ (1|{input_id})\", data=df_model\n",
    "        )\n",
    "    model.fit(\n",
    "        factors={system_id: list(df_model[system_id].unique())},\n",
    "        REML=False,\n",
    "        summarize=False,\n",
    "        verbose=True)\n",
    "    return model\n",
    "\n",
    "def glrt(mod1: Lmer, mod2: Lmer):\n",
    "    chi_square = 2 * abs(mod1.logLike - mod2.logLike)\n",
    "    delta_params = abs(len(mod1.coefs) - len(mod2.coefs))\n",
    "    return {\n",
    "        \"chi_square\": chi_square,\n",
    "        \"df\": delta_params,\n",
    "        \"p\": 1 - stats.chi2.cdf(chi_square, df=delta_params),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting linear model using lmer with Wald confidence intervals...\n",
      "\n",
      "**NOTE**: Column for 'residuals' not created in model.data, but saved in model.resid only. This is because you have rows with NaNs in your data.\n",
      "\n",
      "**NOTE** Column for 'fits' not created in model.data, but saved in model.fits only. This is because you have rows with NaNs in your data.\n",
      "\n",
      "Fitting linear model using lmer with Wald confidence intervals...\n",
      "\n",
      "**NOTE**: Column for 'residuals' not created in model.data, but saved in model.resid only. This is because you have rows with NaNs in your data.\n",
      "\n",
      "**NOTE** Column for 'fits' not created in model.data, but saved in model.fits only. This is because you have rows with NaNs in your data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_fidelity_model_fam=create_model(\"algorithm_family\",fidelity_type=1)\n",
    "grouped_fidelity_model_fam=create_model(\"algorithm_family\",fidelity_type=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(no_fidelity_model_algo.logLike)\n",
    "print(linear_fidelity_model_algo.logLike)\n",
    "print(grouped_fidelity_model_algo.logLike)\n",
    "\n",
    "print(\"GLRT: No fidelity vs. grouped:\")\n",
    "print(glrt(no_fidelity_model_algo,grouped_fidelity_model_algo),end=\"\\n\")\n",
    "print(\"GLRT: No fidelity vs. linear:\")\n",
    "print(glrt(no_fidelity_model_algo,linear_fidelity_model_algo),end=\"\\n\")\n",
    "print(\"GLRT: Grouped fidelity vs. linear:\")\n",
    "print(glrt(linear_fidelity_model_algo,grouped_fidelity_model_algo),end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(no_fidelity_model_fam.logLike)\n",
    "print(linear_fidelity_model_fam.logLike)\n",
    "print(grouped_fidelity_model_fam.logLike)\n",
    "\n",
    "print(\"GLRT: No fidelity vs. grouped:\")\n",
    "print(glrt(no_fidelity_model_fam,grouped_fidelity_model_fam),end=\"\\n\")\n",
    "print(\"GLRT: No fidelity vs. linear:\")\n",
    "print(glrt(no_fidelity_model_fam,linear_fidelity_model_fam),end=\"\\n\")\n",
    "print(\"GLRT: Grouped fidelity vs. linear:\")\n",
    "print(glrt(linear_fidelity_model_fam,grouped_fidelity_model_fam),end=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_10_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
