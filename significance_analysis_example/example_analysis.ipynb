{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymer4 import Lmer\n",
    "import scipy.stats as stats\n",
    "\n",
    "from significance_analysis import conduct_analysis\n",
    "\n",
    "# Load example dataset\n",
    "data = pd.read_csv(\"./example_dataset.csv\")\n",
    "\n",
    "def GLRT(mod1, mod2):\n",
    "    chi_square = 2 * abs(mod1.logLike - mod2.logLike)\n",
    "    delta_params = abs(len(mod1.coefs) - len(mod2.coefs))\n",
    "    return {\n",
    "        \"chi_square\": chi_square,\n",
    "        \"df\": delta_params,\n",
    "        \"p\": 1 - stats.chi2.cdf(chi_square, df=delta_params),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Analysis: Analyse performance of acquisition functions over all benchmarks and trainingrounds\n",
    "data2=data.loc[(data[\"acquisition\"]!=\"ExpectedImprovement\")| (data[\"benchmark\"]!=\"Branin\") ]\n",
    "#conduct_analysis(data2, \"mean\", \"acquisition\", \"benchmark\",show_plots=False,summarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# \"Common\"-Model assumes significant difference, which is why the system-identifier is included\\ncomplex_model = Lmer(\\n                formula=f\"{metric}~{system_id}+{meta_cat}+(1|{input_id})\", data=data3\\n            )\\nsimple_model = Lmer(\\n                formula=f\"{metric}~{system_id}+(1|{input_id})\", data=data3\\n            )\\n            \\n\\n#complex_model = Lmer(\\n#                formula=f\"{metric}~{input_id}+{meta_cat}+(1|{system_id})\", data=data3\\n#            )\\n\\nmeta_dim=\"benchmark_dim\"\\nmeta_cat=\"benchmark_cat\"\\ninput_id=\"acquisition\"\\nsystem_id=\"benchmark\"\\ncomplex_model = Lmer(\\n                formula=f\"{metric}~{meta_dim}+{meta_cat}+(1|{input_id})\", data=data3\\n            )\\nsimple_model = Lmer(\\n                formula=f\"{metric}~{meta_dim}+(1|{input_id})\", data=data3\\n            )\\n\\n# factors specifies names of system_identifier, i.e. Baseline, or Algorithm1\\ncomplex_model.fit(\\n    factors={system_id: list(data[system_id].unique())},\\n    REML=False,\\n    summarize=False,\\n)\\nsimple_model.fit(\\n    factors={system_id: list(data[system_id].unique())},\\n    REML=False,\\n    summarize=False,\\n)\\nprint(GLRT(simple_model, complex_model))\\nprint(complex_model.summary())\\nprint(complex_model.ranef)\\nprint(simple_model.summary())\\nprint(simple_model.ranef)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3=data\n",
    "dimension={\n",
    "    \"Branin\":2,\n",
    "    \"Hartmann6\":6,\n",
    "    \"Jahs_Bench\":10,\n",
    "    \"NN_HPO_Bench\":10\n",
    "}\n",
    "categorical={\n",
    "    \"Branin\":\"Numerical\",\n",
    "    \"Hartmann6\":\"Numerical\",\n",
    "    \"Jahs_Bench\":\"Categorical\",\n",
    "    \"NN_HPO_Bench\":\"Numerical\"\n",
    "}\n",
    "data3[\"benchmark_dim\"]=data3[\"benchmark\"].apply(lambda x:dimension[x])\n",
    "data3[\"benchmark_cat\"]=data3[\"benchmark\"].apply(lambda x:categorical[x])\n",
    "\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "\"\"\"\n",
    "# \"Common\"-Model assumes significant difference, which is why the system-identifier is included\n",
    "complex_model = Lmer(\n",
    "                formula=f\"{metric}~{system_id}+{meta_cat}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "simple_model = Lmer(\n",
    "                formula=f\"{metric}~{system_id}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "            \n",
    "\n",
    "#complex_model = Lmer(\n",
    "#                formula=f\"{metric}~{input_id}+{meta_cat}+(1|{system_id})\", data=data3\n",
    "#            )\n",
    "\n",
    "meta_dim=\"benchmark_dim\"\n",
    "meta_cat=\"benchmark_cat\"\n",
    "input_id=\"acquisition\"\n",
    "system_id=\"benchmark\"\n",
    "complex_model = Lmer(\n",
    "                formula=f\"{metric}~{meta_dim}+{meta_cat}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "simple_model = Lmer(\n",
    "                formula=f\"{metric}~{meta_dim}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "\n",
    "# factors specifies names of system_identifier, i.e. Baseline, or Algorithm1\n",
    "complex_model.fit(\n",
    "    factors={system_id: list(data[system_id].unique())},\n",
    "    REML=False,\n",
    "    summarize=False,\n",
    ")\n",
    "simple_model.fit(\n",
    "    factors={system_id: list(data[system_id].unique())},\n",
    "    REML=False,\n",
    "    summarize=False,\n",
    ")\n",
    "print(GLRT(simple_model, complex_model))\n",
    "print(complex_model.summary())\n",
    "print(complex_model.ranef)\n",
    "print(simple_model.summary())\n",
    "print(simple_model.ranef)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for ['Branin', 'Hartmann6', 'NN_HPO_Bench']\n",
      "P-value: 1.1102230246251565e-16\n",
      "\n",
      "As the p-value 1.1102230246251565e-16 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "                 acquisition  Estimate  2.5_ci  97.5_ci     SE     DF\n",
      "1        ExpectedImprovement     0.384  -4.117    4.885  1.416  3.007\n",
      "2   ProbabilityOfImprovement     0.608  -3.893    5.108  1.416  3.007\n",
      "3       UpperConfidenceBound     0.468  -4.033    4.968  1.416  3.007\n",
      "4       qExpectedImprovement     0.335  -4.166    4.835  1.416  3.007\n",
      "5         qKnowledgeGradient     0.486  -4.015    4.986  1.416  3.007\n",
      "6  qProbabilityOfImprovement     0.774  -3.727    5.275  1.416  3.007\n",
      "7              qSimpleRegret     0.589  -3.911    5.090  1.416  3.007\n",
      "8      qUpperConfidenceBound     0.410  -4.090    4.911  1.416  3.007\n",
      "9               randomSearch     0.960  -3.540    5.461  1.416  3.007\n",
      "The best performing acquisition is qExpectedImprovement, but ['ExpectedImprovement', 'UpperConfidenceBound', 'qKnowledgeGradient', 'qSimpleRegret', 'qUpperConfidenceBound'] are only insignificantly worse.\n",
      "\n",
      "Analysis for ['Jahs_Bench']\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "P-value: 0.0\n",
      "\n",
      "As the p-value 0.0 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "                 acquisition  Estimate  2.5_ci  97.5_ci     SE       DF\n",
      "1        ExpectedImprovement    21.886  21.679   22.094  0.106  45000.0\n",
      "2   ProbabilityOfImprovement    22.563  22.356   22.770  0.106  45000.0\n",
      "3       UpperConfidenceBound    22.110  21.903   22.317  0.106  45000.0\n",
      "4       qExpectedImprovement    22.282  22.075   22.489  0.106  45000.0\n",
      "5         qKnowledgeGradient    23.563  23.356   23.770  0.106  45000.0\n",
      "6  qProbabilityOfImprovement    22.809  22.602   23.016  0.106  45000.0\n",
      "7              qSimpleRegret    21.656  21.449   21.863  0.106  45000.0\n",
      "8      qUpperConfidenceBound    22.418  22.211   22.626  0.106  45000.0\n",
      "9               randomSearch    23.727  23.519   23.934  0.106  45000.0\n",
      "The best performing acquisition is qSimpleRegret, but ['ExpectedImprovement', 'UpperConfidenceBound'] are only insignificantly worse.\n",
      "\n",
      "{'Branin Hartmann6 NN_HPO_Bench': ({'chi_square': 93.29706014448311, 'df': 8, 'p': 1.1102230246251565e-16},                  acquisition  Estimate  2.5_ci  97.5_ci     SE     DF\n",
      "1        ExpectedImprovement     0.384  -4.117    4.885  1.416  3.007\n",
      "2   ProbabilityOfImprovement     0.608  -3.893    5.108  1.416  3.007\n",
      "3       UpperConfidenceBound     0.468  -4.033    4.968  1.416  3.007\n",
      "4       qExpectedImprovement     0.335  -4.166    4.835  1.416  3.007\n",
      "5         qKnowledgeGradient     0.486  -4.015    4.986  1.416  3.007\n",
      "6  qProbabilityOfImprovement     0.774  -3.727    5.275  1.416  3.007\n",
      "7              qSimpleRegret     0.589  -3.911    5.090  1.416  3.007\n",
      "8      qUpperConfidenceBound     0.410  -4.090    4.911  1.416  3.007\n",
      "9               randomSearch     0.960  -3.540    5.461  1.416  3.007), 'Jahs_Bench': ({'chi_square': 356.85118605184834, 'df': 8, 'p': 0.0},                  acquisition  Estimate  2.5_ci  97.5_ci     SE       DF\n",
      "1        ExpectedImprovement    21.886  21.679   22.094  0.106  45000.0\n",
      "2   ProbabilityOfImprovement    22.563  22.356   22.770  0.106  45000.0\n",
      "3       UpperConfidenceBound    22.110  21.903   22.317  0.106  45000.0\n",
      "4       qExpectedImprovement    22.282  22.075   22.489  0.106  45000.0\n",
      "5         qKnowledgeGradient    23.563  23.356   23.770  0.106  45000.0\n",
      "6  qProbabilityOfImprovement    22.809  22.602   23.016  0.106  45000.0\n",
      "7              qSimpleRegret    21.656  21.449   21.863  0.106  45000.0\n",
      "8      qUpperConfidenceBound    22.418  22.211   22.626  0.106  45000.0\n",
      "9               randomSearch    23.727  23.519   23.934  0.106  45000.0)}\n"
     ]
    }
   ],
   "source": [
    "acqu_dict1={'ExpectedImprovement': 'EI', 'ProbabilityOfImprovement': 'PI', 'UpperConfidenceBound': 'UCB', 'qExpectedImprovement': 'EI', 'qKnowledgeGradient': 'KG', 'qProbabilityOfImprovement': 'PI', 'qSimpleRegret': 'SR', 'qUpperConfidenceBound': 'UCB', 'randomSearch': 'RS'}\n",
    "acqu_dict2={'ExpectedImprovement': 'AN', 'ProbabilityOfImprovement': 'AN', 'UpperConfidenceBound': 'AN', 'qExpectedImprovement': 'MC', 'qKnowledgeGradient': 'MC', 'qProbabilityOfImprovement': 'MC', 'qSimpleRegret': 'MC', 'qUpperConfidenceBound': 'MC', 'randomSearch': 'AN'}\n",
    "data3[\"acquisition_fam\"]=data3[\"acquisition\"].apply(lambda x:acqu_dict1[x])\n",
    "data3[\"acquisition_cat\"]=data3[\"acquisition\"].apply(lambda x:acqu_dict2[x])\n",
    "\n",
    "\n",
    "#print(conduct_analysis(data3,metric,\"acquisition_fam\",input_id,show_plots=False,show_contrasts=False, subset=[input_id,dict_keys_to_list(categorical)]))\n",
    "print(conduct_analysis(data3,metric,system_id,input_id,show_plots=False,show_contrasts=False, subset=(input_id,categorical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
