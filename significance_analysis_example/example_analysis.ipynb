{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymer4 import Lmer\n",
    "import scipy.stats as stats\n",
    "\n",
    "from significance_analysis import conduct_analysis\n",
    "\n",
    "# Load example dataset\n",
    "data = pd.read_csv(\"./example_dataset.csv\")\n",
    "\n",
    "def GLRT(mod1, mod2):\n",
    "    chi_square = 2 * abs(mod1.logLike - mod2.logLike)\n",
    "    delta_params = abs(len(mod1.coefs) - len(mod2.coefs))\n",
    "    return {\n",
    "        \"chi_square\": chi_square,\n",
    "        \"df\": delta_params,\n",
    "        \"p\": 1 - stats.chi2.cdf(chi_square, df=delta_params),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Analysis: Analyse performance of acquisition functions over all benchmarks and trainingrounds\n",
    "data2=data.loc[(data[\"acquisition\"]!=\"ExpectedImprovement\")| (data[\"benchmark\"]!=\"Branin\") ]\n",
    "#conduct_analysis(data2, \"mean\", \"acquisition\", \"benchmark\",show_plots=False,summarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# \"Common\"-Model assumes significant difference, which is why the system-identifier is included\\ncomplex_model = Lmer(\\n                formula=f\"{metric}~{system_id}+{meta_cat}+(1|{input_id})\", data=data3\\n            )\\nsimple_model = Lmer(\\n                formula=f\"{metric}~{system_id}+(1|{input_id})\", data=data3\\n            )\\n            \\n\\n#complex_model = Lmer(\\n#                formula=f\"{metric}~{input_id}+{meta_cat}+(1|{system_id})\", data=data3\\n#            )\\n\\nmeta_dim=\"benchmark_dim\"\\nmeta_cat=\"benchmark_cat\"\\ninput_id=\"acquisition\"\\nsystem_id=\"benchmark\"\\ncomplex_model = Lmer(\\n                formula=f\"{metric}~{meta_dim}+{meta_cat}+(1|{input_id})\", data=data3\\n            )\\nsimple_model = Lmer(\\n                formula=f\"{metric}~{meta_dim}+(1|{input_id})\", data=data3\\n            )\\n\\n# factors specifies names of system_identifier, i.e. Baseline, or Algorithm1\\ncomplex_model.fit(\\n    factors={system_id: list(data[system_id].unique())},\\n    REML=False,\\n    summarize=False,\\n)\\nsimple_model.fit(\\n    factors={system_id: list(data[system_id].unique())},\\n    REML=False,\\n    summarize=False,\\n)\\nprint(GLRT(simple_model, complex_model))\\nprint(complex_model.summary())\\nprint(complex_model.ranef)\\nprint(simple_model.summary())\\nprint(simple_model.ranef)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3=data\n",
    "dimension={\n",
    "    \"Branin\":2,\n",
    "    \"Hartmann6\":6,\n",
    "    \"Jahs_Bench\":10,\n",
    "    \"NN_HPO_Bench\":10\n",
    "}\n",
    "categorical={\n",
    "    \"Branin\":\"Numerical\",\n",
    "    \"Hartmann6\":\"Numerical\",\n",
    "    \"Jahs_Bench\":\"Categorical\",\n",
    "    \"NN_HPO_Bench\":\"Numerical\"\n",
    "}\n",
    "data3[\"benchmark_dim\"]=data3[\"benchmark\"].apply(lambda x:dimension[x])\n",
    "data3[\"benchmark_cat\"]=data3[\"benchmark\"].apply(lambda x:categorical[x])\n",
    "\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "\"\"\"\n",
    "# \"Common\"-Model assumes significant difference, which is why the system-identifier is included\n",
    "complex_model = Lmer(\n",
    "                formula=f\"{metric}~{system_id}+{meta_cat}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "simple_model = Lmer(\n",
    "                formula=f\"{metric}~{system_id}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "            \n",
    "\n",
    "#complex_model = Lmer(\n",
    "#                formula=f\"{metric}~{input_id}+{meta_cat}+(1|{system_id})\", data=data3\n",
    "#            )\n",
    "\n",
    "meta_dim=\"benchmark_dim\"\n",
    "meta_cat=\"benchmark_cat\"\n",
    "input_id=\"acquisition\"\n",
    "system_id=\"benchmark\"\n",
    "complex_model = Lmer(\n",
    "                formula=f\"{metric}~{meta_dim}+{meta_cat}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "simple_model = Lmer(\n",
    "                formula=f\"{metric}~{meta_dim}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "\n",
    "# factors specifies names of system_identifier, i.e. Baseline, or Algorithm1\n",
    "complex_model.fit(\n",
    "    factors={system_id: list(data[system_id].unique())},\n",
    "    REML=False,\n",
    "    summarize=False,\n",
    ")\n",
    "simple_model.fit(\n",
    "    factors={system_id: list(data[system_id].unique())},\n",
    "    REML=False,\n",
    "    summarize=False,\n",
    ")\n",
    "print(GLRT(simple_model, complex_model))\n",
    "print(complex_model.summary())\n",
    "print(complex_model.ranef)\n",
    "print(simple_model.summary())\n",
    "print(simple_model.ranef)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for ['Branin', 'Hartmann6', 'NN_HPO_Bench']\n",
      "P-value: 1.1102230246251565e-16\n",
      "\n",
      "As the p-value 1.1102230246251565e-16 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "The best performing acquisition is qExpectedImprovement, but ['ExpectedImprovement', 'UpperConfidenceBound', 'qKnowledgeGradient', 'qSimpleRegret', 'qUpperConfidenceBound'] are only insignificantly worse.\n",
      "\n",
      "Analysis for ['Jahs_Bench']\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "P-value: 0.0\n",
      "\n",
      "As the p-value 0.0 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "The best performing acquisition is qSimpleRegret, but ['ExpectedImprovement', 'UpperConfidenceBound'] are only insignificantly worse.\n",
      "\n",
      "Analysis for ['Branin']\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "P-value: 2.2334027233172904e-06\n",
      "\n",
      "As the p-value 2.2334027233172904e-06 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "The best performing acquisition is ProbabilityOfImprovement, but ['ExpectedImprovement', 'UpperConfidenceBound', 'qExpectedImprovement', 'qKnowledgeGradient', 'qSimpleRegret', 'qUpperConfidenceBound'] are only insignificantly worse.\n",
      "\n",
      "Analysis for ['Hartmann6']\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "P-value: 0.0\n",
      "\n",
      "As the p-value 0.0 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "The best performing acquisition is qKnowledgeGradient, but ['qExpectedImprovement'] are only insignificantly worse.\n",
      "\n",
      "Analysis for ['Jahs_Bench', 'NN_HPO_Bench']\n",
      "P-value: 0.0\n",
      "\n",
      "As the p-value 0.0 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition describes the data as well as the one that does. Therefore there is significant difference within acquisition.\n",
      "\n",
      "P-values adjusted by tukey method for family of 36 estimates\n",
      "The best performing acquisition is qSimpleRegret, but ['ExpectedImprovement', 'UpperConfidenceBound'] are only insignificantly worse.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acqu_dict1={'ExpectedImprovement': 'EI', 'ProbabilityOfImprovement': 'PI', 'UpperConfidenceBound': 'UCB', 'qExpectedImprovement': 'EI', 'qKnowledgeGradient': 'KG', 'qProbabilityOfImprovement': 'PI', 'qSimpleRegret': 'SR', 'qUpperConfidenceBound': 'UCB', 'randomSearch': 'RS'}\n",
    "acqu_dict2={'ExpectedImprovement': 'AN', 'ProbabilityOfImprovement': 'AN', 'UpperConfidenceBound': 'AN', 'qExpectedImprovement': 'MC', 'qKnowledgeGradient': 'MC', 'qProbabilityOfImprovement': 'MC', 'qSimpleRegret': 'MC', 'qUpperConfidenceBound': 'MC', 'randomSearch': 'AN'}\n",
    "data3[\"acquisition_fam\"]=data3[\"acquisition\"].apply(lambda x:acqu_dict1[x])\n",
    "data3[\"acquisition_cat\"]=data3[\"acquisition\"].apply(lambda x:acqu_dict2[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_means=conduct_analysis(data3,metric,system_id,input_id,show_plots=False,show_contrasts=False,summarize=False, subset=(input_id,categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensional_means=conduct_analysis(data3,metric,system_id,input_id,show_plots=False,show_contrasts=False,summarize=False, subset=(input_id,dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 acquisition    mean     SE                    benchmark_cat             benchmark_dim\n",
      "1        ExpectedImprovement   0.384  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "2   ProbabilityOfImprovement   0.608  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "3       UpperConfidenceBound   0.468  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "4       qExpectedImprovement   0.335  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "5         qKnowledgeGradient   0.486  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "6  qProbabilityOfImprovement   0.774  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "7              qSimpleRegret   0.589  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "8      qUpperConfidenceBound   0.410  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "9               randomSearch   0.960  1.416  Branin__Hartmann6__NN_HPO_Bench                       NaN\n",
      "1        ExpectedImprovement  21.886  0.106                       Jahs_Bench                       NaN\n",
      "2   ProbabilityOfImprovement  22.563  0.106                       Jahs_Bench                       NaN\n",
      "3       UpperConfidenceBound  22.110  0.106                       Jahs_Bench                       NaN\n",
      "4       qExpectedImprovement  22.282  0.106                       Jahs_Bench                       NaN\n",
      "5         qKnowledgeGradient  23.563  0.106                       Jahs_Bench                       NaN\n",
      "6  qProbabilityOfImprovement  22.809  0.106                       Jahs_Bench                       NaN\n",
      "7              qSimpleRegret  21.656  0.106                       Jahs_Bench                       NaN\n",
      "8      qUpperConfidenceBound  22.418  0.106                       Jahs_Bench                       NaN\n",
      "9               randomSearch  23.727  0.106                       Jahs_Bench                       NaN\n",
      "1        ExpectedImprovement   3.562  0.177                              NaN                    Branin\n",
      "2   ProbabilityOfImprovement   3.361  0.177                              NaN                    Branin\n",
      "3       UpperConfidenceBound   3.735  0.177                              NaN                    Branin\n",
      "4       qExpectedImprovement   3.465  0.177                              NaN                    Branin\n",
      "5         qKnowledgeGradient   3.937  0.177                              NaN                    Branin\n",
      "6  qProbabilityOfImprovement   4.582  0.177                              NaN                    Branin\n",
      "7              qSimpleRegret   3.702  0.177                              NaN                    Branin\n",
      "8      qUpperConfidenceBound   3.566  0.177                              NaN                    Branin\n",
      "9               randomSearch   4.267  0.177                              NaN                    Branin\n",
      "1        ExpectedImprovement  -2.413  0.014                              NaN                 Hartmann6\n",
      "2   ProbabilityOfImprovement  -1.541  0.014                              NaN                 Hartmann6\n",
      "3       UpperConfidenceBound  -2.335  0.014                              NaN                 Hartmann6\n",
      "4       qExpectedImprovement  -2.464  0.014                              NaN                 Hartmann6\n",
      "5         qKnowledgeGradient  -2.483  0.014                              NaN                 Hartmann6\n",
      "6  qProbabilityOfImprovement  -2.264  0.014                              NaN                 Hartmann6\n",
      "7              qSimpleRegret  -1.937  0.014                              NaN                 Hartmann6\n",
      "8      qUpperConfidenceBound  -2.337  0.014                              NaN                 Hartmann6\n",
      "9               randomSearch  -1.390  0.014                              NaN                 Hartmann6\n",
      "1        ExpectedImprovement  10.945  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "2   ProbabilityOfImprovement  11.283  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "3       UpperConfidenceBound  11.057  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "4       qExpectedImprovement  11.143  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "5         qKnowledgeGradient  11.783  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "6  qProbabilityOfImprovement  11.407  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "7              qSimpleRegret  10.830  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "8      qUpperConfidenceBound  11.211  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n",
      "9               randomSearch  11.865  7.974                              NaN  Jahs_Bench__NN_HPO_Bench\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(categorical_means,dict)\n",
    "training_set=pd.DataFrame(columns=[\"acquisition\",\"mean\",\"SE\"])\n",
    "for category in range(len(categorical_means.keys())):\n",
    "    category_dataset=pd.DataFrame()\n",
    "    category_dataset[[\"acquisition\",\"mean\",\"SE\"]]=categorical_means[list(categorical_means.keys())[category]][1].loc[:,[\"acquisition\",\"Estimate\",\"SE\"]]\n",
    "    category_dataset[\"benchmark_cat\"]=list(categorical_means.keys())[category]\n",
    "    training_set=pd.concat([training_set,category_dataset])\n",
    "for category in range(len(dimensional_means.keys())):\n",
    "    category_dataset=pd.DataFrame()\n",
    "    category_dataset[[\"acquisition\",\"mean\",\"SE\"]]=dimensional_means[list(dimensional_means.keys())[category]][1].loc[:,[\"acquisition\",\"Estimate\",\"SE\"]]\n",
    "    category_dataset[\"benchmark_dim\"]=list(dimensional_means.keys())[category]\n",
    "    training_set=pd.concat([training_set,category_dataset])\n",
    "print(training_set)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
