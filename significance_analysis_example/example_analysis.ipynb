{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymer4 import Lmer\n",
    "import scipy.stats as stats\n",
    "\n",
    "from significance_analysis import conduct_analysis\n",
    "\n",
    "# Load example dataset\n",
    "data = pd.read_csv(\"./example_dataset.csv\")\n",
    "\n",
    "def GLRT(mod1, mod2):\n",
    "    chi_square = 2 * abs(mod1.logLike - mod2.logLike)\n",
    "    delta_params = abs(len(mod1.coefs) - len(mod2.coefs))\n",
    "    return {\n",
    "        \"chi_square\": chi_square,\n",
    "        \"df\": delta_params,\n",
    "        \"p\": 1 - stats.chi2.cdf(chi_square, df=delta_params),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Analysis: Analyse performance of acquisition functions over all benchmarks and trainingrounds\n",
    "data2=data.loc[(data[\"acquisition\"]!=\"ExpectedImprovement\")| (data[\"benchmark\"]!=\"Branin\") ]\n",
    "#conduct_analysis(data2, \"mean\", \"acquisition\", \"benchmark\",show_plots=False,summarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# \"Common\"-Model assumes significant difference, which is why the system-identifier is included\\ncomplex_model = Lmer(\\n                formula=f\"{metric}~{system_id}+{meta_cat}+(1|{input_id})\", data=data3\\n            )\\nsimple_model = Lmer(\\n                formula=f\"{metric}~{system_id}+(1|{input_id})\", data=data3\\n            )\\n            \\n\\n#complex_model = Lmer(\\n#                formula=f\"{metric}~{input_id}+{meta_cat}+(1|{system_id})\", data=data3\\n#            )\\n\\nmeta_dim=\"benchmark_dim\"\\nmeta_cat=\"benchmark_cat\"\\ninput_id=\"acquisition\"\\nsystem_id=\"benchmark\"\\ncomplex_model = Lmer(\\n                formula=f\"{metric}~{meta_dim}+{meta_cat}+(1|{input_id})\", data=data3\\n            )\\nsimple_model = Lmer(\\n                formula=f\"{metric}~{meta_dim}+(1|{input_id})\", data=data3\\n            )\\n\\n# factors specifies names of system_identifier, i.e. Baseline, or Algorithm1\\ncomplex_model.fit(\\n    factors={system_id: list(data[system_id].unique())},\\n    REML=False,\\n    summarize=False,\\n)\\nsimple_model.fit(\\n    factors={system_id: list(data[system_id].unique())},\\n    REML=False,\\n    summarize=False,\\n)\\nprint(GLRT(simple_model, complex_model))\\nprint(complex_model.summary())\\nprint(complex_model.ranef)\\nprint(simple_model.summary())\\nprint(simple_model.ranef)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3=data\n",
    "dimension={\n",
    "    \"Branin\":2,\n",
    "    \"Hartmann6\":6,\n",
    "    \"Jahs_Bench\":10,\n",
    "    \"NN_HPO_Bench\":10\n",
    "}\n",
    "categorical={\n",
    "    \"Branin\":\"Numerical\",\n",
    "    \"Hartmann6\":\"Numerical\",\n",
    "    \"Jahs_Bench\":\"Categorical\",\n",
    "    \"NN_HPO_Bench\":\"Numerical\"\n",
    "}\n",
    "data3[\"benchmark_dim\"]=data3[\"benchmark\"].apply(lambda x:dimension[x])\n",
    "data3[\"benchmark_cat\"]=data3[\"benchmark\"].apply(lambda x:categorical[x])\n",
    "\n",
    "\n",
    "metric=\"mean\"\n",
    "input_id=\"benchmark\"\n",
    "system_id=\"acquisition\"\n",
    "bin_id=\"budget\"\n",
    "\"\"\"\n",
    "# \"Common\"-Model assumes significant difference, which is why the system-identifier is included\n",
    "complex_model = Lmer(\n",
    "                formula=f\"{metric}~{system_id}+{meta_cat}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "simple_model = Lmer(\n",
    "                formula=f\"{metric}~{system_id}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "            \n",
    "\n",
    "#complex_model = Lmer(\n",
    "#                formula=f\"{metric}~{input_id}+{meta_cat}+(1|{system_id})\", data=data3\n",
    "#            )\n",
    "\n",
    "meta_dim=\"benchmark_dim\"\n",
    "meta_cat=\"benchmark_cat\"\n",
    "input_id=\"acquisition\"\n",
    "system_id=\"benchmark\"\n",
    "complex_model = Lmer(\n",
    "                formula=f\"{metric}~{meta_dim}+{meta_cat}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "simple_model = Lmer(\n",
    "                formula=f\"{metric}~{meta_dim}+(1|{input_id})\", data=data3\n",
    "            )\n",
    "\n",
    "# factors specifies names of system_identifier, i.e. Baseline, or Algorithm1\n",
    "complex_model.fit(\n",
    "    factors={system_id: list(data[system_id].unique())},\n",
    "    REML=False,\n",
    "    summarize=False,\n",
    ")\n",
    "simple_model.fit(\n",
    "    factors={system_id: list(data[system_id].unique())},\n",
    "    REML=False,\n",
    "    summarize=False,\n",
    ")\n",
    "print(GLRT(simple_model, complex_model))\n",
    "print(complex_model.summary())\n",
    "print(complex_model.ranef)\n",
    "print(simple_model.summary())\n",
    "print(simple_model.ranef)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for ['Branin', 'Hartmann6', 'NN_HPO_Bench']\n",
      "P-value: 0.030374259978896423\n",
      "\n",
      "As the p-value 0.030374259978896423 is smaller than 0.05, we can reject the Null-Hypothesis that the model that does not consider the acquisition_cat describes the data as well as the one that does. Therefore there is significant difference within acquisition_cat.\n",
      "\n",
      "  acquisition_cat  Estimate  2.5_ci  97.5_ci     SE     DF\n",
      "1              AN     0.605  -3.898    5.108  1.415  3.002\n",
      "2              MC     0.519  -3.984    5.022  1.415  3.001\n",
      "The best performing acquisition_cat is MC, all other perform significantly worse.\n",
      "\n",
      "Analysis for ['Jahs_Bench']\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "boundary (singular) fit: see help('isSingular') \n",
      "\n",
      "P-value: 0.7130985659018074\n",
      "\n",
      "As the p-value 0.7130985659018074 is not smaller than 0.05, we cannot reject the Null-Hypothesis that the model that does not consider the acquisition_cat describes the data as well as the one that does. Therefore there is no significant difference within acquisition_cat\n",
      ".\n",
      "  acquisition_cat  Estimate  2.5_ci  97.5_ci     SE       DF\n",
      "1              AN    22.572  22.468   22.676  0.053  45000.0\n",
      "2              MC    22.546  22.453   22.638  0.047  45000.0\n",
      "The best performing acquisition_cat is MC, but ['AN'] are only insignificantly worse.\n",
      "\n",
      "{'Branin Hartmann6 NN_HPO_Bench': {'chi_square': 4.687984258402139, 'df': 1, 'p': 0.030374259978896423}, 'Jahs_Bench': {'chi_square': 0.1352016871678643, 'df': 1, 'p': 0.7130985659018074}}\n"
     ]
    }
   ],
   "source": [
    "acqu_dict1={'ExpectedImprovement': 'EI', 'ProbabilityOfImprovement': 'PI', 'UpperConfidenceBound': 'UCB', 'qExpectedImprovement': 'EI', 'qKnowledgeGradient': 'KG', 'qProbabilityOfImprovement': 'PI', 'qSimpleRegret': 'SR', 'qUpperConfidenceBound': 'UCB', 'randomSearch': 'RS'}\n",
    "acqu_dict2={'ExpectedImprovement': 'AN', 'ProbabilityOfImprovement': 'AN', 'UpperConfidenceBound': 'AN', 'qExpectedImprovement': 'MC', 'qKnowledgeGradient': 'MC', 'qProbabilityOfImprovement': 'MC', 'qSimpleRegret': 'MC', 'qUpperConfidenceBound': 'MC', 'randomSearch': 'AN'}\n",
    "data3[\"acquisition_fam\"]=data3[\"acquisition\"].apply(lambda x:acqu_dict1[x])\n",
    "data3[\"acquisition_cat\"]=data3[\"acquisition\"].apply(lambda x:acqu_dict2[x])\n",
    "\n",
    "def dict_keys_to_list(dict):\n",
    "  new_dict = {}\n",
    "  for key, value in dict.items():\n",
    "    if value not in new_dict:\n",
    "      new_dict[value] = [key]\n",
    "    else:\n",
    "      if value in new_dict:\n",
    "        new_dict[value].append(key)\n",
    "  return list(new_dict.values())\n",
    "\n",
    "#print(conduct_analysis(data3,metric,\"acquisition_fam\",input_id,show_plots=False,show_contrasts=False, subset=[input_id,dict_keys_to_list(categorical)]))\n",
    "print(conduct_analysis(data3,metric,\"acquisition_cat\",input_id,show_plots=False,show_contrasts=False, subset=(input_id,categorical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
